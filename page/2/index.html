<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Keything的日志</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Keything的日志">
<meta property="og:url" content="http://keything.github.io/page/2/index.html">
<meta property="og:site_name" content="Keything的日志">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Keything的日志">
  
    <link rel="alternate" href="/atom.xml" title="Keything的日志" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Keything的日志</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://keything.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-golang-面向对象编程" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/02/golang-面向对象编程/" class="article-date">
  <time datetime="2019-03-02T07:08:34.000Z" itemprop="datePublished">2019-03-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/02/golang-面向对象编程/">golang-面向对象编程</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>理解golang面向对象</p>
<p>面向对象编程的三个核心是：封装、继承、多态。</p>
<ol>
<li><p>封装(encapsulation)</p>
<p> 封装就是将抽象得到的数据和行为（或功能）相结合，形成一个有机的整体，也就是将数据与操作数据的源代码进行有机的结合，形成“类”，其中数据和函数都是类的成员。</p>
<p> 封装的目的是增强安全性和简化编程，使用者不必了解具体的实现细节，而只是要通过 外部接口，一特定的访问权限来使用类的成员。<br> 即不直接暴露数据，而暴露的是接口.</p>
<p> go封装是package层面的。小写开头的Names只能在包内可见。在一个private package可以隐藏所有东西，并只暴露特定类型、接口、工厂函数。</p>
</li>
</ol>
<ol start="2">
<li><p>继承</p>
<p> 继承是指一个对象直接使用另一对象的属性和方法。事实上，我们遇到的很多实体都有继承的含义。例如，若把汽车看成一个实体，它可以分成多个子实体，如：卡车、公共汽车等。这些子实体都具有汽车的特性，因此，汽车是它们的“父亲”，而这些子实体则是汽车的“孩子”。</p>
</li>
</ol>
<pre><code>现代语言认为实现继承更好的方式是组合(composition)。go采用这种理念，并且没有任何等级内容(hierarchy)。 这允许你使用组合来共享实现的细节。go是通过嵌入(embedding)的方式来实现匿名组合的(anonymous composition)。 

通过嵌入一个匿名类型的组合实现了继承。 嵌入的结构体等同于基类(base class)。当然了也可以嵌入一个接口，但是必须注意，嵌入一个接口时，该结构体必须实现这个接口的方法，不然会报runtime error。

报错：panic: runtime error: invalid memory address or nil pointer dereference
</code></pre><ol start="3">
<li><p>多态（polymorphism）</p>
<p> 多态是允许你将父对象设置成为和一个或更多的子对象相等的技术。赋值会后，父对象就可以根据当前赋值给它的子对象以不同的方式运作。简单来说，允许将子类类型的指针赋值给父类类型的指针。 在C++中都是通过虚函数(Virtual Function)实现的。golang允许接口的子类的多态，但不允许子类替换为父类</p>
</li>
</ol>
<h3 id="实际例子"><a href="#实际例子" class="headerlink" title="实际例子"></a>实际例子</h3><p>在我们实际项目中用到多态的地方很多，举一个例子 获取下游服务的节点列表：<br>需求：</p>
<ul>
<li>希望支持多种方式获取节点列表，比如配置文件、服务发现、http请求等；</li>
<li>希望通过配置获取顺序的方式来实现优先级，比如配置是<code>get_type=服务发现,配置文件,http请求</code>。那么当服务发现获取节点成功时，则使用服务发现；反之如果服务发现获取节点列表失败，则需要使用配置文件的方式。</li>
</ul>
<p>抽象：</p>
<ul>
<li>定义一个接口IConfObj：</li>
<li><p>check函数：为了检查配置文件的配置项是否完备，因为不通获取方式，配置文件不一样；</p>
<pre><code>+ run函数：执行节点获取，并执行 InterfaceAction来执行节点更新。
</code></pre><ul>
<li><p>定义一个获取节点后动作的func，目的就是在获取节点后，通过该func进行操作。         </p>
<pre><code>type IConfObj interface {
    check() error
    run() (bool, error)
}

type InterfaceAction func(hosts []string, is_high_node, is_primary bool) (bool, error)
</code></pre></li>
<li><p>实现节点列表获取配置化</p>
<ul>
<li>不同的获取获取方式实现这个接口，并进行注册。</li>
<li>根据注册先后顺序执行run，如果run成功则结束遍历，反之继续执行直至成功。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>参考文章：</p>
<p><a href="https://code.tutsplus.com/tutorials/lets-go-object-oriented-programming-in-golang--cms-26540" target="_blank" rel="noopener">https://code.tutsplus.com/tutorials/lets-go-object-oriented-programming-in-golang--cms-26540</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2019/03/02/golang-面向对象编程/" data-id="ckw1wzlep002gphnuywk21kes" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/golang/">golang</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-hive的TRANSFORM操作" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/23/hive的TRANSFORM操作/" class="article-date">
  <time datetime="2018-09-23T15:03:39.000Z" itemprop="datePublished">2018-09-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/23/hive的TRANSFORM操作/">hive的TRANSFORM操作</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Transform-Map-Reduce-Syntax"><a href="#Transform-Map-Reduce-Syntax" class="headerlink" title="Transform/Map-Reduce Syntax"></a>Transform/Map-Reduce Syntax</h2><p>hive语言中内置的特性是支持用户自定义mappers/redulers的。 用户可以使用<code>TRANSFROM</code> 子句来内嵌mapper/reduer脚本的。 </p>
<p>By default, columns will be transformed to STRING and delimited by TAB before feeding to the user script; similarly, all NULL values will be converted to the literal string \N in order to differentiate NULL values from empty strings. The standard output of the user script will be treated as TAB-separated STRING columns, any cell containing only \N will be re-interpreted as a NULL, and then the resulting STRING column will be cast to the data type specified in the table declaration in the usual way. User scripts can output debug information to standard error which will be shown on the task detail page on hadoop. These defaults can be overridden with ROW FORMAT ….</p>
<p>注意：</p>
<p>Formally, MAP … and REDUCE … are syntactic transformations of SELECT TRANSFORM ( … ). In other words, they serve as comments or notes to the reader of the query. BEWARE: Use of these keywords may be dangerous as (e.g.) typing “REDUCE” does not force a reduce phase to occur and typing “MAP” does not force a new map phase!</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">clusterBy: CLUSTER BY colName (&apos;,&apos; colName)*</span><br><span class="line">distributeBy: DISTRIBUTE BY colName (&apos;,&apos; colName)*</span><br><span class="line">sortBy: SORT BY colName (ASC | DESC)? (&apos;,&apos; colName (ASC | DESC)?)*</span><br><span class="line"> </span><br><span class="line">rowFormat</span><br><span class="line">  : ROW FORMAT</span><br><span class="line">    (DELIMITED [FIELDS TERMINATED BY char]</span><br><span class="line">               [COLLECTION ITEMS TERMINATED BY char]</span><br><span class="line">               [MAP KEYS TERMINATED BY char]</span><br><span class="line">               [ESCAPED BY char]</span><br><span class="line">               [LINES SEPARATED BY char]</span><br><span class="line">     |</span><br><span class="line">     SERDE serde_name [WITH SERDEPROPERTIES</span><br><span class="line">                            property_name=property_value,</span><br><span class="line">                            property_name=property_value, ...])</span><br><span class="line"> </span><br><span class="line">outRowFormat : rowFormat</span><br><span class="line">inRowFormat : rowFormat</span><br><span class="line">outRecordReader : RECORDREADER className</span><br><span class="line"> </span><br><span class="line">query:</span><br><span class="line">  FROM (</span><br><span class="line">    FROM src</span><br><span class="line">    MAP expression (&apos;,&apos; expression)*</span><br><span class="line">    (inRowFormat)?</span><br><span class="line">    USING &apos;my_map_script&apos;</span><br><span class="line">    ( AS colName (&apos;,&apos; colName)* )?</span><br><span class="line">    (outRowFormat)? (outRecordReader)?</span><br><span class="line">    ( clusterBy? | distributeBy? sortBy? ) src_alias</span><br><span class="line">  )</span><br><span class="line">  REDUCE expression (&apos;,&apos; expression)*</span><br><span class="line">    (inRowFormat)?</span><br><span class="line">    USING &apos;my_reduce_script&apos;</span><br><span class="line">    ( AS colName (&apos;,&apos; colName)* )?</span><br><span class="line">    (outRowFormat)? (outRecordReader)?</span><br><span class="line"> </span><br><span class="line">  FROM (</span><br><span class="line">    FROM src</span><br><span class="line">    SELECT TRANSFORM &apos;(&apos; expression (&apos;,&apos; expression)* &apos;)&apos;</span><br><span class="line">    (inRowFormat)?</span><br><span class="line">    USING &apos;my_map_script&apos;</span><br><span class="line">    ( AS colName (&apos;,&apos; colName)* )?</span><br><span class="line">    (outRowFormat)? (outRecordReader)?</span><br><span class="line">    ( clusterBy? | distributeBy? sortBy? ) src_alias</span><br><span class="line">  )</span><br><span class="line">  SELECT TRANSFORM &apos;(&apos; expression (&apos;,&apos; expression)* &apos;)&apos;</span><br><span class="line">    (inRowFormat)?</span><br><span class="line">    USING &apos;my_reduce_script&apos;</span><br><span class="line">    ( AS colName (&apos;,&apos; colName)* )?</span><br><span class="line">    (outRowFormat)? (outRecordReader)?</span><br></pre></td></tr></table></figure>
<p>转化的例子1：</p>
<p><code>FROM (
  FROM pv_users
  MAP pv_users.userid, pv_users.date
  USING &#39;map_script&#39;
  AS dt, uid
  CLUSTER BY dt) map_output
INSERT OVERWRITE TABLE pv_users_reduced
  REDUCE map_output.dt, map_output.uid
  USING &#39;reduce_script&#39;
  AS date, count;
FROM (
  FROM pv_users
  SELECT TRANSFORM(pv_users.userid, pv_users.date)
  USING &#39;map_script&#39;
  AS dt, uid
  CLUSTER BY dt) map_output
INSERT OVERWRITE TABLE pv_users_reduced
  SELECT TRANSFORM(map_output.dt, map_output.uid)
  USING &#39;reduce_script&#39;
  AS date, count;</code></p>
<p>转化的例子2：</p>
<p><code>FROM (
  FROM src
  SELECT TRANSFORM(src.key, src.value) ROW FORMAT SERDE &#39;org.apache.hadoop.hive.contrib.serde2.TypedBytesSerDe&#39;
  USING &#39;/bin/cat&#39;
  AS (tkey, tvalue) ROW FORMAT SERDE &#39;org.apache.hadoop.hive.contrib.serde2.TypedBytesSerDe&#39;
  RECORDREADER &#39;org.apache.hadoop.hive.contrib.util.typedbytes.TypedBytesRecordReader&#39;
) tmap
INSERT OVERWRITE TABLE dest1 SELECT tkey, tvalue</code></p>
<p>将TRANSFORM的输出打出来</p>
<p>脚本的输出默认是string，如果想进行类型转换的需要进行如下操作。</p>
<p><code>SELECT TRANSFORM(stuff)
USING &#39;script&#39;
AS thing1, thing2</code></p>
<p>类型转化<br><code>SELECT TRANSFORM(stuff)
USING &#39;script&#39;
AS (thing1 INT, thing2 INT)</code></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2018/09/23/hive的TRANSFORM操作/" data-id="ckw1wzlev002wphnulwz9xa54" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-hive权威指南学习笔记" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/23/hive权威指南学习笔记/" class="article-date">
  <time datetime="2018-09-23T15:02:05.000Z" itemprop="datePublished">2018-09-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/23/hive权威指南学习笔记/">hive权威指南学习笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Hive操作</p>
<p>本篇文章是对 <code>https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-DDLOperations</code> </p>
<p>以及</p>
<p>《Hive编程指南》的学习总结</p>
<ol>
<li>DDL Operations (data defination language)</li>
</ol>
<ul>
<li>create table pokes (foo INT, bar STRING);</li>
<li>create table invites (foo INT, bar STRING) PARTITIONED BY (ds STRING);</li>
</ul>
<p>partition column 是一个虚拟列，并不是数据本身的一部分，但是可以获得某一份特定数据集。 </p>
<ul>
<li>show tables;</li>
<li>show tables ‘.*s’</li>
<li>describe invites;</li>
</ul>
<ol start="2">
<li>DML Operations (data manipulation language)</li>
</ol>
<h3 id="2-1-装载数据"><a href="#2-1-装载数据" class="headerlink" title="2.1 装载数据"></a>2.1 装载数据</h3><ul>
<li>LOAD DATA LOCAL INPUT ‘./examples/files/kv1.txt’ OVERWRITE INTO TABLE pokes;</li>
<li>LOAD DATA LOCAL INPATH ‘./examples/files/kv2.txt’ OVERWRITE INTO TABLE invites PARTITION (ds=’2008-08-15’);</li>
<li>LOAD DATA LOCAL INPATH ‘./examples/files/kv3.txt’ OVERWRITE INTO TABLE invites PARTITION (ds=’2008-08-08’);</li>
</ul>
<p><code>LOCAL</code> 表明这是在本地文件系统上的文件；如果没有的话，那么就从hdfs上获取文件。</p>
<p><code>OVERWRITE</code> 表明表中已经存在的数据将会被删除。 如果没有的话，数据文件被添加到已经存在的数据集合中。 </p>
<h3 id="2-2-通过查询语句插入数据"><a href="#2-2-通过查询语句插入数据" class="headerlink" title="2.2 通过查询语句插入数据"></a>2.2 通过查询语句插入数据</h3><ul>
<li><code>FROM staged_employees se 
INSERT OVERWRITE TABLE employee PARTITION (country = &#39;US&#39; and state = &#39;OR&#39;) select *  where se.country = &#39;US&#39; and se.state = &#39;OR&#39;
INSERT OVERWRITE TABLE employee PARTITION (country = &#39;US&#39; and state = &#39;CA&#39;) select *  where se.country = &#39;US&#39; and se.state = &#39;CA&#39;</code></li>
</ul>
<h4 id="动态分区插入"><a href="#动态分区插入" class="headerlink" title="动态分区插入"></a>动态分区插入</h4><p>前面的语法中有一个问题，即：如果需要创建非常多的分区，那么用户就需要写非常多的SQL。<br>幸运的是：Hive提供了一个动态分区功能，可以基于查询参数推断出需要创建的分区名称。相比之下，前面看到的都是静态分区。 </p>
<p><code>INSERT OVERWRITE TABLE employees PARTITION (country, state) 
 SELECT ..., se.cnty, se.st FROM staged_employees se;</code></p>
<p>注意：Hive 根据SELECT语句中最后2列来确定分区字段country和state的值。<br>而不是根据命名来匹配的。</p>
<p>在SQL语句使用不同的命名就是为了强调源表字段值和输出分区值直接的关系是根据位置而不是根据命名来匹配的。 </p>
<h3 id="2-3-单个查询语句中创建表并加载数据"><a href="#2-3-单个查询语句中创建表并加载数据" class="headerlink" title="2.3 单个查询语句中创建表并加载数据"></a>2.3 单个查询语句中创建表并加载数据</h3><ul>
<li>create table u_data_v2 as SELECT userid, rating from u_data limit 10;</li>
</ul>
<h3 id="2-4-导出数据"><a href="#2-4-导出数据" class="headerlink" title="2.4 导出数据"></a>2.4 导出数据</h3><ul>
<li>INSERT OVERWRITE LOCAL DIRECTORY ‘/tmp/hive’ SELECT userid, rating FROM u_data; </li>
</ul>
<ol start="3">
<li>SQL操作</li>
</ol>
<h3 id="SELECT-…-FROM-语句"><a href="#SELECT-…-FROM-语句" class="headerlink" title="SELECT … FROM 语句"></a>SELECT … FROM 语句</h3><p>3.1 数据类型</p>
<p> 当用户选择的列是集合数据类型时，Hive会使用JSON语法进行输出。</p>
<ul>
<li>当列是一个数组时，其值使用一个括在<code>[...]</code>的逗号分隔的列进行表示，如[“Mary Smith”, “Todd Jones”]</li>
<li>当列是一个Map时，使用JSON格式来表达map，即使用一个被括在<code>{...}</code>内的以逗号分隔的键值对列表进行表示；如 <code>{&quot;Federal Taxes&quot;:0.2 &quot;State Taxes&quot;: 0.05}</code></li>
<li>当列是一个Struct时，使用map格式来表示，如<code>{&quot;Federal Taxes&quot;:0.2 &quot;State Taxes&quot;: 0.05}</code></li>
</ul>
<p>引用元素的方式：</p>
<ul>
<li>引用Map元素，使用ARRAY[…]语法；</li>
<li>引用Struct的一个元素，使用<code>点</code>符号。</li>
</ul>
<p>3.2 使用函数</p>
<p>3.3 列别名</p>
<p>如果新产生的结果在源表中不存在的话，通常有必要给这些新产生的列起一个名称，也就是别名。 </p>
<ul>
<li>select userid as uid from u_data;</li>
</ul>
<p>3.4 嵌套SELECT 语句</p>
<p><code>FROM (
    SELECT upper(name), salary ,deductions[&quot;Federal Taxes&quot;] as fed_taxes FROM employees
    ) e
SELECT e.name, e.fed_taxes where e.name = &quot;yan&quot;</code></p>
<p>从这个嵌套语句中可以看到，我们将前面的结果集起了个别名，称之为e，在这个语句外面嵌套查询了name fed_taxes两个字段。 同时约束name必须是yan。</p>
<p>3.5 CASE … WHEN … THEN 句式</p>
<p>CASE .. WHEN .. THEN 语句和if条件语句类似，用于处理单个列的查询结果。 </p>
<p><code>SELECT userid, movieid, 
    CASE 
    WHEN rating &lt;= 1 THEN &quot;low&quot; 
    WHEN rating &gt; 1 and rating &lt;= 3 THEN &quot;middle&quot; ELSE &quot;high&quot;  
    END  as level 
    from u_data limit 10;</code></p>
<h3 id="4-WHERE-语句-（对应Hive编程指南的6-2-WHERE语句）"><a href="#4-WHERE-语句-（对应Hive编程指南的6-2-WHERE语句）" class="headerlink" title="4. WHERE 语句 （对应Hive编程指南的6.2 WHERE语句）"></a>4. WHERE 语句 （对应Hive编程指南的6.2 WHERE语句）</h3><h4 id="4-1-WHERE语句不能使用列别名。"><a href="#4-1-WHERE语句不能使用列别名。" class="headerlink" title="4.1  WHERE语句不能使用列别名。"></a>4.1  WHERE语句不能使用<code>列别名</code>。</h4><p><code>SELECT name, salary,  salary * (1-deductions[&quot;Federal Taxes&quot;]) as salary_minus_fed_taxes 
FROM employees
WHERE round(salary * (1-deductions[&quot;Federal Taxes&quot;])) &gt; 70000</code></p>
<p>这个查询语句里面，有重复的表达式。下面的查询语句使用一个列别名来消除重复问题，但是并不能生效。 </p>
<p><code>SELECT name, salary,  salary * (1-deductions[&quot;Federal Taxes&quot;]) as salary_minus_fed_taxes 
FROM employees
WHERE round(salary_minus_fed_taxes) &gt; 70000;
报错：Invalid table alias or column reference &#39;salary_minus_fed_taxes&#39;</code></p>
<p>正如错误信息所提示的，WHERE语句不能使用<code>列别名</code>。<br>不过我们可以使用一个嵌套的SELECT语句</p>
<p><code>SELECT e.* FROM 
(SELECT name,salary, salary * (1-deductions[&quot;Federal Taxes&quot;]) as salary_minus_fed_taxes FROM employees) e 
WHERE round(e.salary_minus_fed_taxes) &gt; 70000;</code></p>
<h4 id="4-2-谓词操作符"><a href="#4-2-谓词操作符" class="headerlink" title="4.2 谓词操作符"></a>4.2 谓词操作符</h4><h4 id="4-3-GROUP-BY语句"><a href="#4-3-GROUP-BY语句" class="headerlink" title="4.3 GROUP BY语句"></a>4.3 GROUP BY语句</h4><p>GROUP BY 通常会和聚合函数一起使用，按照一个或者多个列队结果进行分组，然后对每个组执行聚合操作。 </p>
<h3 id="4-4-JOIN-语句"><a href="#4-4-JOIN-语句" class="headerlink" title="4.4 JOIN 语句"></a>4.4 JOIN 语句</h3><p>Hive支持通常的SQL JOIN语句，但是只支持<code>等值连接</code>，并且在ON子句中只支持AND。</p>
<p>4.4.1 INNER JOIN</p>
<p><code>SELECT a.ymd, a.price_close, b.price_close, c.price_close 
FROM stocks a JOIN stocks b ON a.ymd = b.ymd
              JOIN stocks c ON a.ymd = c.ymd
WHERE a.symbol = &#39;AAPL&#39; AND b.symbol = &#39;IBM&#39; AND c.symbol = &#39;GE&#39;;</code></p>
<p>在这个例子中，会首先启动一个MapReduce job对表a和表b进行连接操作，然后会再启动一个MapReduce job将第一个MapReduce job的输出和表c进行连接操作。 </p>
<p>Hive表总是按照从左到右的顺序执行的。 </p>
<h4 id="JOIN优化"><a href="#JOIN优化" class="headerlink" title="JOIN优化"></a>JOIN优化</h4><p>Hive同时假定查询中最后一个表是最大的那个表。在对每行记录进行连接操作时，它会尝试将其他表缓存起来，然后扫描最后那个表进行计算。</p>
<p>因此用户需要保证<code>连续查询中的表的大小是从左到右依次增加的</code>。</p>
<h4 id="LEFT-OUTER-JOIN"><a href="#LEFT-OUTER-JOIN" class="headerlink" title="LEFT OUTER JOIN"></a>LEFT OUTER JOIN</h4><h4 id="OUTER-JOIN"><a href="#OUTER-JOIN" class="headerlink" title="OUTER JOIN"></a>OUTER JOIN</h4><h4 id="RIGHT-OUTER-JOIN"><a href="#RIGHT-OUTER-JOIN" class="headerlink" title="RIGHT OUTER JOIN"></a>RIGHT OUTER JOIN</h4><h4 id="FULL-OUTER-JOIN"><a href="#FULL-OUTER-JOIN" class="headerlink" title="FULL OUTER JOIN"></a>FULL OUTER JOIN</h4><h4 id="LEFT-SEMI-JOIN"><a href="#LEFT-SEMI-JOIN" class="headerlink" title="LEFT SEMI-JOIN"></a>LEFT SEMI-JOIN</h4><h4 id="笛卡尔积JOIN"><a href="#笛卡尔积JOIN" class="headerlink" title="笛卡尔积JOIN"></a>笛卡尔积JOIN</h4><h4 id="map-side-JOIN"><a href="#map-side-JOIN" class="headerlink" title="map-side JOIN"></a>map-side JOIN</h4><h3 id="4-5-ORDER-BY-和-SORT-BY"><a href="#4-5-ORDER-BY-和-SORT-BY" class="headerlink" title="4.5 ORDER BY 和 SORT BY"></a>4.5 ORDER BY 和 SORT BY</h3><h3 id="4-6-含有SORT-BY-的DISTRIBUTE-BY"><a href="#4-6-含有SORT-BY-的DISTRIBUTE-BY" class="headerlink" title="4.6 含有SORT BY 的DISTRIBUTE BY"></a>4.6 含有SORT BY 的DISTRIBUTE BY</h3><h3 id="4-10-UNION-ALL"><a href="#4-10-UNION-ALL" class="headerlink" title="4.10 UNION ALL"></a>4.10 UNION ALL</h3><p>UNION ALL将2个或多个进行合并。每个union子查询都必须有相同的列，并且每个字段的字段类型必须是一致的。</p>
<p>比如，如果第2个字段是FLOAT类型，那么所有其他子查询的第2个字段必须都是FLOAT类型的。</p>
<p>举例，将日志数据进行合并的例子:</p>
<p><code>SELECT log.ymd, log.level, log.message 
    FROM(
            SELECT l1.ymd, l1.level, l1.message, &#39;Log1&#39; AS source
            FROM log1 l1
        UNION ALL
            SELECT l2.ymd, l2.level, l2.message, &#39;Log2&#39; AS source
            FROM log2 l2 
        ) log
    SORT BY log.ymd ASC;</code></p>
<h2 id="5-视图（hive编程指南第7章-视图）"><a href="#5-视图（hive编程指南第7章-视图）" class="headerlink" title="5 视图（hive编程指南第7章 视图）"></a>5 视图（hive编程指南第7章 视图）</h2><p>3.3 一些用法</p>
<ul>
<li>SELECT a.* FROM invites a WHERE a.ds=’2008-08-15’;</li>
<li>FROM pokes t1 JOIN invites t2 ON (t1.bar = t2.bar) INSERT OVERWRITE TABLE events SELECT t1.bar, t1.foo, t2.foo;</li>
<li><p>CREATE TABLE u_data (<br>userid INT,<br>movieid INT,<br>rating INT,<br>unixtime STRING)<br>ROW FORMAT DELIMITED<br>FIELDS TERMINATED BY ‘\t’<br>STORED AS TEXTFILE;</p>
</li>
<li><p>LOAD DATA LOCAL INPATH ‘/Users/keything/Downloads/ml-100k/u.data’ OVERWRITE INTO TABLE u_data;</p>
</li>
<li><code>SELECT COUNT(*) FROM u_data;</code></li>
</ul>
<p>一个简单的例子：</p>
<p>创建表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE u_data (</span><br><span class="line">  userid INT,</span><br><span class="line">  movieid INT,</span><br><span class="line">  rating INT,</span><br><span class="line">  unixtime STRING)</span><br><span class="line">ROW FORMAT DELIMITED</span><br><span class="line">FIELDS TERMINATED BY &apos;\t&apos;</span><br><span class="line">STORED AS TEXTFILE;</span><br></pre></td></tr></table></figure>
<p>获取数据集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget http://files.grouplens.org/datasets/movielens/ml-100k.zip</span><br><span class="line">unzip ml-100k.zip</span><br></pre></td></tr></table></figure>
<p>加载数据集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA LOCAL INPATH &apos;&lt;path&gt;/u.data&apos; OVERWRITE INTO TABLE u_data;</span><br></pre></td></tr></table></figure>
<p>创建weekday_mapper.py</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import datetime</span><br><span class="line"></span><br><span class="line">for line in sys.stdin:</span><br><span class="line">  line = line.strip()</span><br><span class="line">  userid, movieid, rating, unixtime = line.split(&apos;\t&apos;)</span><br><span class="line">  weekday = datetime.datetime.fromtimestamp(float(unixtime)).isoweekday()</span><br><span class="line">  print &apos;\t&apos;.join([userid, movieid, rating, str(weekday)])</span><br></pre></td></tr></table></figure>
<p>对于这个脚本是否正确，可以通过自己创建文件来验证。</p>
<p>创建mapper脚本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE u_data_new (</span><br><span class="line">  userid INT,</span><br><span class="line">  movieid INT,</span><br><span class="line">  rating INT,</span><br><span class="line">  weekday INT)</span><br><span class="line">ROW FORMAT DELIMITED</span><br><span class="line">FIELDS TERMINATED BY &apos;\t&apos;;</span><br><span class="line"></span><br><span class="line">add FILE weekday_mapper.py;</span><br><span class="line"></span><br><span class="line">INSERT OVERWRITE TABLE u_data_new</span><br><span class="line">SELECT</span><br><span class="line">  TRANSFORM (userid, movieid, rating, unixtime)</span><br><span class="line">  USING &apos;python weekday_mapper.py&apos;</span><br><span class="line">  AS (userid, movieid, rating, weekday)</span><br><span class="line">FROM u_data;</span><br><span class="line"></span><br><span class="line">SELECT weekday, COUNT(*)</span><br><span class="line">FROM u_data_new</span><br><span class="line">GROUP BY weekday;</span><br></pre></td></tr></table></figure>
<p>最后得到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1	12254</span><br><span class="line">2	13579</span><br><span class="line">3	14430</span><br><span class="line">4	15114</span><br><span class="line">5	14743</span><br><span class="line">6	18229</span><br><span class="line">7	11651</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2018/09/23/hive权威指南学习笔记/" data-id="ckw1wzles002ophnum4fyd5ax" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-hadoop权威指南第四版学习笔记" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/23/hadoop权威指南第四版学习笔记/" class="article-date">
  <time datetime="2018-09-23T03:30:21.000Z" itemprop="datePublished">2018-09-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/23/hadoop权威指南第四版学习笔记/">hadoop权威指南第四版学习笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Hadoop权威指南第四版-学习笔记"><a href="#Hadoop权威指南第四版-学习笔记" class="headerlink" title="Hadoop权威指南第四版-学习笔记"></a>Hadoop权威指南第四版-学习笔记</h1><h2 id="第二章-关于MapReduce"><a href="#第二章-关于MapReduce" class="headerlink" title="第二章 关于MapReduce"></a>第二章 关于MapReduce</h2><p>MapReduce是一种可用于数据处理的编程模型。 </p>
<p>Hadoop将MapReduce的输入数据划分成等长的小数据块，称为输入分片（input split) 或简称“分片”。hadoop为每个分片构建一个map任务，并由该任务来运行用户自定义的map函数，从而处理分片中的每条记录。 </p>
<p>一个合理的分片大小趋向于HDFS的一个块的大小，默认是128MB。</p>
<h4 id="map任务将其输出写入本地硬盘，而非HDFS。这是为什么呢-？"><a href="#map任务将其输出写入本地硬盘，而非HDFS。这是为什么呢-？" class="headerlink" title="map任务将其输出写入本地硬盘，而非HDFS。这是为什么呢 ？"></a>map任务将其输出写入本地硬盘，而非HDFS。这是为什么呢 ？</h4><p>因为map的输出是中间结果：该中间结果由reduce任务处理后才产生最终输出结果，而且一旦作业完成，map的输出结果就可以删除。 因此，如果把map输出存储在HDFS中并实现备份，难免有些小题大做。 </p>
<p>如果运行map任务的节点在map中间结果传送给reduce任务之前失败，hadoop将在另一个节点重新运行这个map任务以再次构建map中间结果。</p>
<p>reduce任务并不具备数据本地化的优势，单个reduce任务的输入通常来自于所有mapper的输出。</p>
<p>reduce任务的数量并不是由输入数据的大小决定，相反是独立指定的。<br>如果有多个reduce任务，每个map任务就会针对输出进行分区(partition)，即为每个reduce任务建一个分区，每个分区有许多键（及其对应的值），但每个键对应的key-value 都在同一个分区中。 用户可以使用自定义的分区函数控制分区，但通常使用默认的partitioner 通过哈希函数来区分，很高效。</p>
<p>一般情况下，多个reduce任务的数据流如图2-4所示，该图清楚表明了为什么map任务和reduce任务之间的数据流成为shuffle（混洗），因为每个reduce任务的输入都来自许多map任务。shuffle一般比图中所示的更复杂，而且调整混洗参数对作业总执行时间的影响非常大。 </p>
<h2 id="第三章-Hadoop分布式文件系统"><a href="#第三章-Hadoop分布式文件系统" class="headerlink" title="第三章 Hadoop分布式文件系统"></a>第三章 Hadoop分布式文件系统</h2><h3 id="3-2-HDFS概念"><a href="#3-2-HDFS概念" class="headerlink" title="3.2 HDFS概念"></a>3.2 HDFS概念</h3><p>3.2.1 数据块</p>
<p>HDFS同样也有块block的概念，默认是128MB。</p>
<p>3.2.2 namenode和datanode</p>
<p>HDFS集群有两类节点，以 管理节点-工作节点 模式运行，即一个namenode（管理节点）和多个datanode（工作节点）。<br>namenode 管理文件系统的命名空间。它维护者文件系统树及整颗树内所有的文件和目录。这些信息以两个文件形式永久保存在本地磁盘上：命名空间镜像文件和编辑日志文件。 </p>
<p>namenode也记录着每个文件中各个块所在的数据节点信息，但它并不用就保存块的位置信息，因为这些信息会在系统启动时根据数据节点信息重建。 </p>
<p>datanode是文件系统的工作节点。他们根据需要存储并检索数据块（受客户端或namenode调度），并且定期向namenode发送所存储的块的列表。</p>
<p>3.2.3 块缓存<br>3.2.4 联邦HDFS<br>3.2.5 HDFS的高可用性</p>
<h3 id="3-3-命令行接口"><a href="#3-3-命令行接口" class="headerlink" title="3.3 命令行接口"></a>3.3 命令行接口</h3><h3 id="3-4-Hadoop-文件系统"><a href="#3-4-Hadoop-文件系统" class="headerlink" title="3.4 Hadoop 文件系统"></a>3.4 Hadoop 文件系统</h3><h3 id="3-5-Java接口"><a href="#3-5-Java接口" class="headerlink" title="3.5 Java接口"></a>3.5 Java接口</h3><h3 id="3-6-数据流"><a href="#3-6-数据流" class="headerlink" title="3.6 数据流"></a>3.6 数据流</h3><p>3.6.1 剖析文件读取<br>3.6.2 剖析文件写入<br>3.6.3 一致性模型</p>
<h2 id="第4章-关于YARN"><a href="#第4章-关于YARN" class="headerlink" title="第4章  关于YARN"></a>第4章  关于YARN</h2><p>Apache YARN(Yet Another Resource Negotiator的缩写)是Hadoop的集群资源管理系统。</p>
<h2 id="第5章-Hadoop的I-O-操作"><a href="#第5章-Hadoop的I-O-操作" class="headerlink" title="第5章 Hadoop的I/O 操作"></a>第5章 Hadoop的I/O 操作</h2><p>5.1 数据完整性<br>5.2 压缩</p>
<p>5.2.1 codec<br>5.2.2 压缩和输入分片</p>
<p>5.4 基于文件的数据结构</p>
<h2 id="第6章-MapReduce应用开发"><a href="#第6章-MapReduce应用开发" class="headerlink" title="第6章 MapReduce应用开发"></a>第6章 MapReduce应用开发</h2><p>MapReduce编程遵循一个特定的流程。首先写map函数和reduce函数，最好使用单元测试来确保函数的运行符合预期。 然后写一个驱动程序来运行作业。</p>
<h2 id="第7章-MapReduce的工作机制"><a href="#第7章-MapReduce的工作机制" class="headerlink" title="第7章 MapReduce的工作机制"></a>第7章 MapReduce的工作机制</h2><h3 id="7-3-shuffle和排序"><a href="#7-3-shuffle和排序" class="headerlink" title="7.3 shuffle和排序"></a>7.3 shuffle和排序</h3><p>MapReduce确保每个reducer的输入都是按键排序的。</p>
<p>系统执行排序、将map输出作为输入传给reducer的过程称为shuffle。</p>
<p>7.3.1 map端</p>
<p>map函数开始产生输出时，并不是简单地将它写到磁盘。这个过程更复杂，利用缓冲的方式写到内存并出于效率的考虑进行预排序。<br>每个map任务都有一个环形内存缓冲区用于存储任务输出。在默认情况下，缓冲区大小是100mb。一旦缓冲内容达到阈值，一个后台线程便开始把内容溢出到splill到磁盘。</p>
<p>在溢出写到磁盘过程中，map输出继续写到缓存区，但如果在此期间缓冲区被填满，map会被阻塞直到写磁盘过程完成。 </p>
<p>在写磁盘之前，线程首先根据数据最终要传的reduer 将数据划分成相应的分区(partition)。在每个分区中，后台线程按键进行内存中排序，如果有一个combiner函数，它就在排序后的输出上运行。运行combiner函数使得map输出结果更紧凑。</p>
<p>每次内存缓冲区达到溢出阈值，就会新建一个溢出文件spill file，因此在map任务写完最后一个输出记录之后，会有几个溢出文件。</p>

<p>7.3.2 reduce端</p>
<h3 id="7-4-任务的执行"><a href="#7-4-任务的执行" class="headerlink" title="7.4 任务的执行"></a>7.4 任务的执行</h3><h2 id="第8章"><a href="#第8章" class="headerlink" title="第8章"></a>第8章</h2><p>8.1 MapReduce的类型</p>
<p>Hadoop的MapReduce中，map函数和reduce函数遵循如下常规格式：</p>
<p>map:(k1, v1) -&gt; list(k2, v2)<br>combiner: (k2, list(v2)) -&gt; list(k2, v2)<br>reduce:(k2, list(v2)) -&gt; list(k3, v3)</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2018/09/23/hadoop权威指南第四版学习笔记/" data-id="ckw1wzles002qphnusy8qhf6r" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-spark的sql学习" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/22/spark的sql学习/" class="article-date">
  <time datetime="2018-09-22T13:19:27.000Z" itemprop="datePublished">2018-09-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/22/spark的sql学习/">spark的sql学习</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Spark-SQL-DataFrames-and-Datasets-Guide"><a href="#Spark-SQL-DataFrames-and-Datasets-Guide" class="headerlink" title="Spark SQL, DataFrames and Datasets Guide"></a>Spark SQL, DataFrames and Datasets Guide</h1><p>##概述：</p>
<p>Spark SQL时候spark中处理结构化数据的模块。 </p>
<p>Spark SQL可以从已经安装好的hive中读取数据，也可以通过命令行 or JDBC/ODBC 读取数据。 </p>
<h3 id="Datasets-and-DataFrames"><a href="#Datasets-and-DataFrames" class="headerlink" title="Datasets and DataFrames:"></a>Datasets and DataFrames:</h3><p>Dataset 是数据的分布式集合（A Dataset is a distributed collection of data）。Dataset可以从JVM对象中构建，也可以使用转化进行操作（transformations 如map,flatMap,filter 等等)。</p>
<p>DataFrame 是将Dataset组织为命名列(named columns)，在python/R 中等同于关系型数据库中的表(table)。</p>
<h3 id="DataFrame-Operations："><a href="#DataFrame-Operations：" class="headerlink" title="DataFrame Operations："></a>DataFrame Operations：</h3><p>df.printSchema()<br>df.select(“name”).show()<br>df.select(df[‘name’], df[‘age’] + 1).show()<br>df.filter(df[‘age’] &gt; 21).show()<br>df.groupBy(“age”).count().show()</p>
<p>Running SQL Queries Programmatically</p>
<p>在SparkSession中的sql函数会执行sql查询语句，并返回 DataFrame的结果。<br>sqlDF = spark.sql(“SELECT * FROM people”)<br>sqlDF.show()</p>
<h3 id="Programmatically-Specifying-the-Schema"><a href="#Programmatically-Specifying-the-Schema" class="headerlink" title="Programmatically Specifying the Schema"></a>Programmatically Specifying the Schema</h3><p>官方引导的方式个人感觉有点繁琐。 <a href="http://spark.apache.org/docs/latest/sql-programming-guide.html#programmatically-specifying-the-schema" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/sql-programming-guide.html#programmatically-specifying-the-schema</a></p>
<p>可以使用to.DF()的方式来做。 </p>
<figure class="highlight plain"><figcaption><span>org.apache.spark.sql.types._</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import Row</span><br><span class="line"></span><br><span class="line">lines =  sc.textFile(&quot;file:///usr/local/Cellar/spark/2.0.1/examples/src/main/resources/people.txt&quot;)</span><br><span class="line">parts = lines.map(lambda l: l.split(&quot;,&quot;))</span><br><span class="line">peoples  = parts.map(lambda p: Row(name=p[0], age=p[1]))</span><br><span class="line">peoples.toDF()</span><br><span class="line"></span><br><span class="line">// Creates a temporary view using the DataFrame</span><br><span class="line">peopleDF.createOrReplaceTempView(&quot;people&quot;)</span><br><span class="line"></span><br><span class="line">// SQL can be run over a temporary view created using DataFrames</span><br><span class="line">val results = spark.sql(&quot;SELECT name FROM people&quot;)</span><br></pre></td></tr></table></figure>
<h2 id="Data-Sources"><a href="#Data-Sources" class="headerlink" title="Data Sources"></a>Data Sources</h2><p>Spark SQL 通过DataFrame接口 支持不同类型的数据源。<br>将DataFrame注册为一个临时视图（temporary view)，允许你可以通过SQL查询数据。<br>这部分描述的是加载和保存数据的通用方法，并会介绍built-in data sources的特殊选项。</p>
<h3 id="Generic-Load-Save-Functions"><a href="#Generic-Load-Save-Functions" class="headerlink" title="Generic Load/Save Functions"></a>Generic Load/Save Functions</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = spark.read.load(&quot;examples/src/main/resources/users.parquet&quot;)</span><br><span class="line">df.select(&quot;name&quot;, &quot;favorite_color&quot;).write.save(&quot;namesAndFavColors.parquet&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="手工指定特殊参数"><a href="#手工指定特殊参数" class="headerlink" title="手工指定特殊参数"></a>手工指定特殊参数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = spark.read.load(&quot;examples/src/main/resources/people.json&quot;, format=&quot;json&quot;)</span><br><span class="line">df.select(&quot;name&quot;, &quot;age&quot;).write.save(&quot;namesAndAges.parquet&quot;, format=&quot;parquet&quot;)</span><br></pre></td></tr></table></figure>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#-*- coding:utf-8 -*-</span><br><span class="line"></span><br><span class="line">import sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf8&apos;)</span><br><span class="line">import json</span><br><span class="line">import subprocess</span><br><span class="line">import time</span><br><span class="line">import pandas as pd</span><br><span class="line">from pyspark.sql import Row</span><br><span class="line"></span><br><span class="line">import math</span><br><span class="line">from datetime import datetime, timedelta</span><br><span class="line">from pyspark import SparkContext, SparkConf</span><br><span class="line">from pyspark import HiveContext</span><br><span class="line">import collections</span><br><span class="line"></span><br><span class="line">def hiveSql():</span><br><span class="line">    sql = &apos;&apos;&apos;</span><br><span class="line">    select param[&apos;datatype&apos;] as datatype</span><br><span class="line">     from xxx between aaa and bbb</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    return sql</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def parse_poi(row):</span><br><span class="line">    # 第二列取值：</span><br><span class="line">    # 1 参数错误并且经纬度为0，</span><br><span class="line">    # 2 参数错误并且经纬度不是0</span><br><span class="line">    # 3 query为空</span><br><span class="line">    # 4 其他异常情况</span><br><span class="line">    parse_result = &quot;empty\tempty\tempty&quot;</span><br><span class="line">    json_str = row.json_str</span><br><span class="line">    if type(json_str) != str and type(json_str) != unicode:</span><br><span class="line">        return parse_result</span><br><span class="line">    try:</span><br><span class="line">        res = json.loads(json_str)</span><br><span class="line">    except:</span><br><span class="line">        return parse_result</span><br><span class="line"></span><br><span class="line">    if row.searchname != &apos;&apos;:</span><br><span class="line">        parse_result = &apos;%s\t%s\t%s&apos;%(row.nnn, 0, row.oooo)</span><br><span class="line">        return parse_result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def parse_mmm(sc):</span><br><span class="line">    hc = HiveContext(sc)</span><br><span class="line"></span><br><span class="line">    all_sug_poi = sc.parallelize([])</span><br><span class="line">    sql = hiveSql()</span><br><span class="line">    print sql</span><br><span class="line">    df = hc.sql(sql)</span><br><span class="line">    mmmm = df.rdd.map(parse_poi).map(lambda x:x.split(&quot;\t&quot;))</span><br><span class="line"></span><br><span class="line">    ooooo = mmmm.map(lambda p: Row(searchname=p[0], stattype=p[1], datatype=p[2]))</span><br><span class="line"></span><br><span class="line">    dudtf = ooooo.toDF()</span><br><span class="line">    dudtf.printSchema()</span><br><span class="line">    dudtf.groupBy(&apos;stattype&apos;).count().show()</span><br><span class="line">    dudtf.groupBy(&apos;stattype&apos;, &apos;datatype&apos;).count().show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    conf = SparkConf()</span><br><span class="line">    conf.setAppName(&apos;mmmmxxxx&apos;)</span><br><span class="line">    sc = SparkContext(conf = conf)</span><br><span class="line">    parse_mmm(sc)</span><br></pre></td></tr></table></figure>
<p>在这个例子中，</p>
<ul>
<li>首先查询hive，要使用HiveContext去查询。</li>
<li>再次，由于数据存在一定的污染，因此在进行json.loads之前必须对row.json_str进行类型断言；并且当json.loads抛出异常时，进行捕获。</li>
<li>在执行mmmm.map时使用map，而不是flatMap。</li>
<li></li>
</ul>
<p>##参考文章：</p>
<ul>
<li><a href="http://spark.apache.org/docs/latest/sql-programming-guide.html" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/sql-programming-guide.html</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2018/09/22/spark的sql学习/" data-id="ckw1wzlfp004qphnuc68pg41p" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/">spark</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-机器学习-chapter1-梯度下降" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/27/机器学习-chapter1-梯度下降/" class="article-date">
  <time datetime="2018-07-27T12:18:28.000Z" itemprop="datePublished">2018-07-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/27/机器学习-chapter1-梯度下降/">机器学习-chapter1-梯度下降</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>数学知识：高等数学第六版下册&lt;同济大学数学系&gt; 第八章和第九章知识<br>机器学习理论：<br>代码实现：<a href="https://ctmakro.github.io/site/on_learning/gd.html" target="_blank" rel="noopener">https://ctmakro.github.io/site/on_learning/gd.html</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2018/07/27/机器学习-chapter1-梯度下降/" data-id="ckw1wzlfx005cphnu8r282h3a" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine-learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-cpp-libconfig" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/05/28/cpp-libconfig/" class="article-date">
  <time datetime="2018-05-28T02:50:46.000Z" itemprop="datePublished">2018-05-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/05/28/cpp-libconfig/">cpp_libconfig</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="参考处："><a href="#参考处：" class="headerlink" title="参考处："></a>参考处：</h2><p><a href="https://hyperrealm.github.io/libconfig/" target="_blank" rel="noopener">https://hyperrealm.github.io/libconfig/</a></p>
<h2 id="简单用法"><a href="#简单用法" class="headerlink" title="简单用法"></a>简单用法</h2><p>libconfig::Config 的方法</p>
<pre><code>#include &lt;libconfig.h++&gt;
#include &lt;iostream&gt;

int main() {
    try {
        libconfig::Config config;
        config.readFile(&quot;config.ini&quot;);
        const libconfig::Setting&amp; serverConf = config.lookup(&quot;server&quot;);
        int serverPort;
        bool flag = serverConf.lookupValue(&quot;service_port&quot;, serverPort);
        std::cout &lt;&lt; &quot;server port &quot; &lt;&lt; serverPort &lt;&lt; std::endl;
    } catch (const libconfig::ConfigException&amp; e) {
        std::cout &lt;&lt; &quot;exception:&quot; &lt;&lt; e.what() &lt;&lt; std::endl;
    }
}
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2018/05/28/cpp-libconfig/" data-id="ckw1wzlec001lphnu9jwvb41i" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cpp-lib/">cpp-lib</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-faiss-tutorial" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/10/faiss-tutorial/" class="article-date">
  <time datetime="2018-04-10T07:40:44.000Z" itemprop="datePublished">2018-04-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/10/faiss-tutorial/">faiss-tutorial</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2018/04/10/faiss-tutorial/" data-id="ckw1wzlej0020phnu2ghyu7dt" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-faiss-install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/10/faiss-install/" class="article-date">
  <time datetime="2018-04-10T06:48:07.000Z" itemprop="datePublished">2018-04-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/10/faiss-install/">faiss-install</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>一、clone faiss项目</p>
<p>git clone <a href="https://github.com/facebookresearch/faiss.git" target="_blank" rel="noopener">https://github.com/facebookresearch/faiss.git</a></p>
<p>二、安装必要依赖和工具</p>
<ul>
<li><p>conda install openblas</p>
</li>
<li><p>brew install llvm</p>
</li>
<li><p>如果提示:dyld: Library not loaded: @rpath/libomp.dylib</p>
<ul>
<li>ln -s $HOME/anaconda2/lib/libopenblas.dylib /usr/lib/libopenblas.dylib</li>
<li>export DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:/usr/local/opt/llvm/lib/</li>
</ul>
</li>
<li><p>make tests/test_blas</p>
</li>
</ul>
<p>常见错误：</p>
<ul>
<li><p>fatal error: ‘stdio.h’ file not found</p>
<ul>
<li>解决：xcode-select –install</li>
</ul>
</li>
<li><p>fatal error: ‘malloc.h’ file not found</p>
<ul>
<li>IndexScalarQuantizer.cpp 中 malloc.h 改成 sys/malloc.h</li>
</ul>
</li>
</ul>
<p>三、编译安装c++部分</p>
<ul>
<li>make all</li>
<li>./demos/demo_ivfpq_indexing</li>
</ul>
<p>四、安装faiss的python部分</p>
<ul>
<li><p>which python</p>
<ul>
<li>/usr/local/Cellar/anaconda2/bin/python</li>
<li>建议使用anaconda的python</li>
</ul>
</li>
<li><p>make py</p>
</li>
<li><p>python -c “import faiss”</p>
</li>
</ul>
<p>五、 centos按照</p>
<ul>
<li><p>安装依赖</p>
<p>  sudo yum install -y openblas swig</p>
</li>
<li><p>获取 faiss 源代码</p>
<p>  git clone <a href="https://github.com/facebookresearch/faiss.git" target="_blank" rel="noopener">https://github.com/facebookresearch/faiss.git</a></p>
</li>
<li><p>编译 faiss</p>
<p>  cd faiss<br>  cp example_makefiles/makefile.inc.Linux makefile.inc<br>  make all</p>
</li>
<li><p>编译 python 接口</p>
<p>  make py</p>
</li>
<li><p>设置优化选项</p>
<p>  export OMP_WAIT_POLICY=PASSIVE</p>
</li>
<li><p>运行 python 示例代码</p>
<p> export PYTHONPATH=.<br> python tutorial/python/1-Flat.py<br> python tutorial/python/2-IVFFlat.py<br> python tutorial/python/3-IVFPQ.py</p>
</li>
</ul>
<p>五、参考文章</p>
<ul>
<li><a href="https://github.com/facebookresearch/faiss/blob/master/INSTALL.md" target="_blank" rel="noopener">https://github.com/facebookresearch/faiss/blob/master/INSTALL.md</a></li>
<li><a href="https://www.mobibrw.com/2017/6235" target="_blank" rel="noopener">https://www.mobibrw.com/2017/6235</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2018/04/10/faiss-install/" data-id="ckw1wzlef001vphnuaegg5v8s" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/faiss/">faiss</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-开发中容易出现的特殊字符编码" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/06/开发中容易出现的特殊字符编码/" class="article-date">
  <time datetime="2018-03-06T05:25:02.000Z" itemprop="datePublished">2018-03-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/06/开发中容易出现的特殊字符编码/">开发中容易出现的特殊字符编码</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://www.jianshu.com/p/0f43c5e37762" target="_blank" rel="noopener">https://www.jianshu.com/p/0f43c5e37762</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2018/03/06/开发中容易出现的特殊字符编码/" data-id="ckw1wzlfy005fphnulv5c8tl5" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/3/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Laravel/">Laravel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/composer/">composer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cpp/">cpp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cpp-lib/">cpp-lib</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/faiss/">faiss</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/">git</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go-source-code/">go.source.code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/golang/">golang</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/laravel/">laravel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mac/">mac</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/">machine-learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/memcache/">memcache</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/">mysql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nginx/">nginx</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nosql/">nosql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/octave/">octave</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/php/">php</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/php源码学习/">php源码学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/redis/">redis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/">spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tcp/">tcp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/thrift/">thrift</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分布式/">分布式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/基础知识/">基础知识</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Laravel/" style="font-size: 10px;">Laravel</a> <a href="/tags/composer/" style="font-size: 10px;">composer</a> <a href="/tags/cpp/" style="font-size: 12.22px;">cpp</a> <a href="/tags/cpp-lib/" style="font-size: 10px;">cpp-lib</a> <a href="/tags/elasticsearch/" style="font-size: 11.11px;">elasticsearch</a> <a href="/tags/faiss/" style="font-size: 10px;">faiss</a> <a href="/tags/git/" style="font-size: 12.22px;">git</a> <a href="/tags/go-source-code/" style="font-size: 10px;">go.source.code</a> <a href="/tags/golang/" style="font-size: 16.67px;">golang</a> <a href="/tags/laravel/" style="font-size: 11.11px;">laravel</a> <a href="/tags/linux/" style="font-size: 14.44px;">linux</a> <a href="/tags/mac/" style="font-size: 13.33px;">mac</a> <a href="/tags/machine-learning/" style="font-size: 10px;">machine-learning</a> <a href="/tags/memcache/" style="font-size: 15.56px;">memcache</a> <a href="/tags/mysql/" style="font-size: 13.33px;">mysql</a> <a href="/tags/nginx/" style="font-size: 13.33px;">nginx</a> <a href="/tags/nosql/" style="font-size: 18.89px;">nosql</a> <a href="/tags/octave/" style="font-size: 10px;">octave</a> <a href="/tags/php/" style="font-size: 20px;">php</a> <a href="/tags/php源码学习/" style="font-size: 17.78px;">php源码学习</a> <a href="/tags/redis/" style="font-size: 12.22px;">redis</a> <a href="/tags/spark/" style="font-size: 12.22px;">spark</a> <a href="/tags/tcp/" style="font-size: 10px;">tcp</a> <a href="/tags/thrift/" style="font-size: 13.33px;">thrift</a> <a href="/tags/分布式/" style="font-size: 10px;">分布式</a> <a href="/tags/基础知识/" style="font-size: 15.56px;">基础知识</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">December 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">November 2015</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/11/16/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2021/11/16/elasticsearch路由规则学习/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/11/16/Spark-DataSource-Hive Tables/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/11/16/Starting Point- SparkSession/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/11/16/RedisCluster详细说明[翻译]/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 Keything<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>