<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>spark_learn | Keything的日志</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="RDD介绍在Spark集群背后，有一个非常重要的分布式数据架构，即弹性分布式数据集（resilient distributed dataset, RDD)，它是逻辑集中的实体，在集群中的多台机器上进行数据分区。通过多台机器上不同RDD分区的控制，就能够减少机器之间的数据重排（data shuffling）。Spark提供了partitionBy运算符，能够通过集群中多台机器对原始RDD进行数据再分">
<meta name="keywords" content="spark">
<meta property="og:type" content="article">
<meta property="og:title" content="spark_learn">
<meta property="og:url" content="http://keything.github.io/2017/03/31/spark-learn/index.html">
<meta property="og:site_name" content="Keything的日志">
<meta property="og:description" content="RDD介绍在Spark集群背后，有一个非常重要的分布式数据架构，即弹性分布式数据集（resilient distributed dataset, RDD)，它是逻辑集中的实体，在集群中的多台机器上进行数据分区。通过多台机器上不同RDD分区的控制，就能够减少机器之间的数据重排（data shuffling）。Spark提供了partitionBy运算符，能够通过集群中多台机器对原始RDD进行数据再分">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2021-11-16T09:45:21.266Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="spark_learn">
<meta name="twitter:description" content="RDD介绍在Spark集群背后，有一个非常重要的分布式数据架构，即弹性分布式数据集（resilient distributed dataset, RDD)，它是逻辑集中的实体，在集群中的多台机器上进行数据分区。通过多台机器上不同RDD分区的控制，就能够减少机器之间的数据重排（data shuffling）。Spark提供了partitionBy运算符，能够通过集群中多台机器对原始RDD进行数据再分">
  
    <link rel="alternate" href="/atom.xml" title="Keything的日志" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Keything的日志</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://keything.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-spark-learn" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/31/spark-learn/" class="article-date">
  <time datetime="2017-03-31T15:07:37.000Z" itemprop="datePublished">2017-03-31</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      spark_learn
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="RDD介绍"><a href="#RDD介绍" class="headerlink" title="RDD介绍"></a>RDD介绍</h2><p>在Spark集群背后，有一个非常重要的分布式数据架构，即弹性分布式数据集（resilient distributed dataset, RDD)，它是逻辑集中的实体，在集群中的多台机器上进行数据分区。通过多台机器上不同RDD分区的控制，就能够减少机器之间的数据重排（data shuffling）。Spark提供了<code>partitionBy</code>运算符，能够通过集群中多台机器对原始RDD进行数据再分配来创建一个新的RDD。</p>
<p>RDD是Spark的核心数据结构，通过RDD的依赖关系形成Spark的调度顺序。通过对RDD的操作形成整个Spark程序。</p>
<p>###一、 RDD的两种创建方式</p>
<h4 id="1-代码中并行化一个已经存在的集合-Parallelized-Collections"><a href="#1-代码中并行化一个已经存在的集合-Parallelized-Collections" class="headerlink" title="1. 代码中并行化一个已经存在的集合(Parallelized Collections)"></a>1. 代码中并行化一个已经存在的集合(Parallelized Collections)</h4><pre><code>从已经存在集合中创建

    data = [1, 2, 3, 4, 5]
    distData = sc.parallelize(data)


集合并行化（parallel collections）的一个重要参数是：集合切分的分区数。Spark会为集群中每个分区运行一个任务。一般是集群中每个CPU有2-4个分区。通常，Spark会根据集群情况自动设置分区的数量。当然，你也可以手工输入一个数量，作为parallelize的第二个参数（如 `sc.parallelize(data, 10)`)
一旦创建以后，数据就可以并行处理了。
</code></pre><h4 id="2-从外部存储系统中创建。如共享文件系统，HDFS，HBASE，HIVE或其他提供Hadoop输入格式的数据来源"><a href="#2-从外部存储系统中创建。如共享文件系统，HDFS，HBASE，HIVE或其他提供Hadoop输入格式的数据来源" class="headerlink" title="2. 从外部存储系统中创建。如共享文件系统，HDFS，HBASE，HIVE或其他提供Hadoop输入格式的数据来源"></a>2. 从外部存储系统中创建。如共享文件系统，HDFS，HBASE，HIVE或其他提供Hadoop输入格式的数据来源</h4><p>可以使用SparkContext’s textFile方法创建文本文件RDDs。这个方法使用文件的URL（或者机器的本地文件, hdfs:://, s3n://等等），并作为行的集合进行读取。<br>从Hadoop获取的方式：</p>
<pre><code>sc.textFile(&quot;your_hdfs_path&quot;)
</code></pre><p>从Hive中获取：</p>
<pre><code>import org.apache.spark.sql.SQLContext
val hc = new org.apache.spark.sql.hive.HiveContext(sc)
val df = hc.sql(&quot;show databases&quot;)
df.show
</code></pre><p>####使用spark读取文件的注意事项：<br>如果使用本地文件系统，If using a path on the local filesystem, the file must also be accessible at the same path on worker nodes. Either copy the file to all workers or use a network-mounted shared file system.</p>
<p>所有spark的基于文件的输入方法，包含<code>textFile</code>，支持目录、压缩文件、wildcards等。例如，可以使用<code>textFile(&quot;/my/directory&quot;)</code>, <code>textFile(&quot;/my/directory/*.txt&quot;)</code>, <code>textFile(&quot;/my/directory/*.gz&quot;)</code>.</p>
<p><code>textFile</code>方法可以有第二个参数用于控制分区的个数。默认spark会为每一个文件block创建一个分区（hdfs中默认block是64MB），但是你可以传递更大的分区数。注意，分区数不能少于block数量。</p>
<p>除了<code>textFile</code>， spark的python api还支持许多其他格式：</p>
<ul>
<li><code>SparkContext.wholeTextFiles</code>,</li>
<li><code>RDD.saveAsPickleFile</code>, <code>SparkContext.pickleFil</code></li>
<li>SequenceFile and Hadoop Input/Output Formats</li>
</ul>
<p>###二、 RDD的操作<br>RDDs支持两种类型的操作：transformations（从已经存在的Rdd创建一个新的数据集合）和 actions（对数据集合运算后返回一个值）。例如：<code>map</code>是一个传入每个数据集合的元素并返回一个新的RDD的transformations。另一方面，<code>reduce</code>是一个action：使用一个函数对RDD中所有元素进行聚合，并返回一个最后结果。</p>
<p>在Spark中所有的transformations都是惰性的，并不会马上计算。它只是记录了在base dataset上应用了哪些transformations。只有在有actions的时候才会真的计算。这样的设计使得spark的运行更加高效。</p>
<p>默认，每次进行actions的时候，已经转换过的RDD还需要重新计算。当然，你可以使用<code>persist(or cache)</code>方法进行持久化。</p>
<ol>
<li>分类</li>
</ol>
<pre><code>+ Transformation和Action两个维度
+ 在Transformation维度会细分为：Value数据类型和Key-value对数据类型。Value类型封装在RDD类中直接使用，Key-Value对数据类型封装在PairRDDFunctions类中，用户需要引入`import org.apache.spark.SparkContext._`才能够使用。
</code></pre><h3 id="三、RDD的Value型Transformation操作详细说明"><a href="#三、RDD的Value型Transformation操作详细说明" class="headerlink" title="三、RDD的Value型Transformation操作详细说明"></a>三、RDD的Value型Transformation操作详细说明</h3><h4 id="输入分区与输出分区是一对一型"><a href="#输入分区与输出分区是一对一型" class="headerlink" title="输入分区与输出分区是一对一型"></a>输入分区与输出分区是一对一型</h4><ol>
<li><p>map</p>
<p> 将函数应用于Rdd的每个元素，并返回结果作为一个新的RDD。<br> Applies a transformation function on each item of the RDD and returns the result as a new RDD.</p>
</li>
</ol>
<pre><code>举例：


    &gt;&gt;&gt; data = [&quot;hello&quot;, &quot;world12&quot;, &quot;nihao&quot;]
    &gt;&gt;&gt; rdd = sc.parallelize(data)
    &gt;&gt;&gt; maprdd = rdd.map(lambda x: len(x))
    &gt;&gt;&gt; maprdd.collect()
        [5, 7, 5]
    &gt;&gt;&gt; total=maprdd.reduce(lambda a,b:a+b)

    &gt;&gt;&gt; print total
        17
</code></pre><p>   实例2：</p>
<pre><code>&gt;&gt;&gt; m = sc.parallelize([&quot;dog&quot;, &quot;tiger&quot;, &quot;lion&quot;])
&gt;&gt;&gt; n = m.map(lambda x: (x, 1))
&gt;&gt;&gt; n.collect()
[(&apos;dog&apos;, 1), (&apos;tiger&apos;, 1), (&apos;lion&apos;, 1)]
</code></pre><ol start="2">
<li><p>flatMap</p>
<p> 与map类似，但是允许在映射中释放多个元素。</p>
<p> 举例：</p>
<pre><code>&gt;&gt;&gt; data = [&quot;hello&quot;, &quot;world12&quot;, &quot;nihao&quot;]
&gt;&gt;&gt; rdd.map(lambda x: (x,x)).collect()
    [(&apos;hello&apos;, &apos;hello&apos;), (&apos;world12&apos;, &apos;world12&apos;), (&apos;nihao&apos;, &apos;nihao&apos;)]
&gt;&gt;&gt; rdd.flatMap(lambda x: (x,x)).collect()
    [&apos;hello&apos;, &apos;hello&apos;, &apos;world12&apos;, &apos;world12&apos;, &apos;nihao&apos;, &apos;nihao&apos;]
</code></pre></li>
<li><p>mapPartitions</p>
</li>
<li>glom</li>
</ol>
<h4 id="输入分区与输出分区多对一型"><a href="#输入分区与输出分区多对一型" class="headerlink" title="输入分区与输出分区多对一型"></a>输入分区与输出分区多对一型</h4><ol>
<li><p>union</p>
<p> 执行标准集合操作：A union B。并不进行去重操作，保存所有元素。如果想去重，可以使用distince()。</p>
<pre><code>&gt;&gt;&gt; datamm = sc.parallelize([1,2,3,4,5]).union(sc.parallelize([4,5,6,7,8]))
&gt;&gt;&gt; datamm.collect()
    [1, 2, 3, 4, 5, 4, 5, 6, 7, 8]
</code></pre></li>
<li><p>cartesian</p>
<p> 对两个RDD内所有元素进行笛卡尔积操作。<br> Computes the cartesian product between two RDDs </p>
</li>
</ol>
<h4 id="输入分区与输出分区多对多"><a href="#输入分区与输出分区多对多" class="headerlink" title="输入分区与输出分区多对多"></a>输入分区与输出分区多对多</h4><ol>
<li><p>groupBy：将元素按照函数生成相应的key，数据就转换为key-value格式，之后将key相同的元素分为一组。</p>
<pre><code>&gt;&gt;&gt; m = sc.parallelize([&quot;tiger&quot;, &quot;mmmmm&quot;, &quot;nnn&quot;, &quot;hhh&quot;])
&gt;&gt;&gt; n = m.groupBy(len)
&gt;&gt;&gt; n.collect()
[(5, &lt;pyspark.resultiterable.ResultIterable object at 0x106acbed0&gt;), (3, &lt;pyspark.resultiterable.ResultIterable object at 0x106acbb50&gt;)]
&gt;&gt;&gt; def tra(k_records):
...     k = k_records[0]
...     print &quot;k=&quot;,k
...     records = k_records[1]
...     for record in records:
...         print &quot;record:&quot;, record
...
&gt;&gt;&gt; o = n.map(tra)
&gt;&gt;&gt; o.collect()
k= 3
record: nnn
record: hhh
k= 5
record: tiger
record: mmmmm
[None, None]
</code></pre></li>
</ol>
<h4 id="输出分区为输入分区子类型"><a href="#输出分区为输入分区子类型" class="headerlink" title="输出分区为输入分区子类型"></a>输出分区为输入分区子类型</h4><ol>
<li><p>filter: 对元素进行过滤，对每个元素应用f函数，返回值为true的元素保留；反之，过滤。</p>
<pre><code>&gt;&gt;&gt; def tigerFilter(x):
...     if x == &quot;tiger&quot;:
...             return 0
...     else:
...             return 1
...
&gt;&gt;&gt; m = sc.parallelize([&quot;tiger&quot;, &quot;mmmmm&quot;, &quot;nnn&quot;, &quot;hhh&quot;])
&gt;&gt;&gt; m.filter(tigerFilter).collect()
[&apos;mmmmm&apos;, &apos;nnn&apos;, &apos;hhh&apos;]
</code></pre></li>
<li>distinct：将RDD中的元素进行去重操作。</li>
<li>subtract:相当于进行集合的差操作。         </li>
<li>sample</li>
<li>cache</li>
</ol>
<h3 id="Key-Value型Transformation算子"><a href="#Key-Value型Transformation算子" class="headerlink" title="Key-Value型Transformation算子"></a>Key-Value型Transformation算子</h3><ol>
<li>mapValues:针对(key, value)中的value进行操作，而不对key进行处理</li>
<li><p>对单个RDD或两个RDD聚集</p>
<ul>
<li>combineByKey</li>
<li>reduceByKey</li>
<li>partitionBy</li>
</ul>
</li>
<li><p>连接</p>
<ul>
<li>join</li>
<li>leftOutJoin</li>
</ul>
</li>
</ol>
<h2 id="Action算子"><a href="#Action算子" class="headerlink" title="Action算子"></a>Action算子</h2><ol>
<li>无输出 foreach</li>
<li><p>HDFS</p>
<ul>
<li>saveAsTextFile</li>
<li>saveAsObjectFile</li>
</ul>
</li>
<li><p>Scala集合和数据类型</p>
<ul>
<li>collect</li>
<li>collectAsMap</li>
<li>lookup</li>
<li>reduceByKeyLocally</li>
<li>count</li>
<li>top</li>
<li>reduce</li>
<li>fold</li>
<li>aggregate</li>
<li></li>
</ul>
</li>
</ol>
<h4 id="working-with-key-value-Pairs"><a href="#working-with-key-value-Pairs" class="headerlink" title="working with key-value Pairs"></a>working with key-value Pairs</h4><p>有一些特别的操作只能应用于k/v对。最常见的是分布式重排操作（distributed shuffle)，如通过key进行grouping, aggregating。</p>
<h2 id="Spark学习"><a href="#Spark学习" class="headerlink" title="Spark学习"></a>Spark学习</h2><h2 id="spark函数学习"><a href="#spark函数学习" class="headerlink" title="spark函数学习"></a>spark函数学习</h2><ol>
<li><p>spark函数讲解 aggregate</p>
<ul>
<li><a href="https://www.iteblog.com/archives/1268" target="_blank" rel="noopener">https://www.iteblog.com/archives/1268</a></li>
<li><a href="http://lib.csdn.net/article/scala/34642==" target="_blank" rel="noopener">http://lib.csdn.net/article/scala/34642==</a></li>
</ul>
</li>
<li><p>所有spark函数讲解</p>
<ul>
<li><a href="http://homepage.cs.latrobe.edu.au/zhe/ZhenHeSparkRDDAPIExamples.html" target="_blank" rel="noopener">http://homepage.cs.latrobe.edu.au/zhe/ZhenHeSparkRDDAPIExamples.html</a></li>
</ul>
</li>
</ol>
<h3 id="Spark数据输入"><a href="#Spark数据输入" class="headerlink" title="Spark数据输入"></a>Spark数据输入</h3><ol>
<li><p>从HDFS读取日志文件</p>
<p> var file = sc.textFile(“hdfs://xxx”)</p>
</li>
</ol>
<h3 id="Spark中数据处理"><a href="#Spark中数据处理" class="headerlink" title="Spark中数据处理"></a>Spark中数据处理</h3><ol>
<li><p>过滤</p>
<p> var errors = file.filter(line =&gt; line.contains(“error”)</p>
</li>
</ol>
<p>aggregate函数</p>
<p><a href="http://lib.csdn.net/article/scala/34642" target="_blank" rel="noopener">理解Spark RDD中的aggregate函数</a><br><a href="http://homepage.cs.latrobe.edu.au/zhe/ZhenHeSparkRDDAPIExamples.html" target="_blank" rel="noopener">learn</a></p>
<p>groupBy函数</p>
<p>combineByKey函数<br>countByKey函数<br>reduce<br>reduceByKey<br>sortBy<br>sortByKey</p>
<p>S</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2017/03/31/spark-learn/" data-id="ckw5yuflw004qtznunjey5q4b" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/">spark</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/03/31/自动化测试/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          自动化测试
        
      </div>
    </a>
  
  
    <a href="/2017/01/16/thrift-demo/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">thrift-demo</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Laravel/">Laravel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Redis/">Redis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/composer/">composer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cpp/">cpp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cpp-lib/">cpp-lib</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/faiss/">faiss</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/">git</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go-source-code/">go.source.code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/golang/">golang</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/laravel/">laravel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mac/">mac</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/">machine-learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/memcache/">memcache</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/">mysql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nginx/">nginx</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nosql/">nosql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/octave/">octave</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/php/">php</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/php源码学习/">php源码学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/redis/">redis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/">spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tcp/">tcp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/thrift/">thrift</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分布式/">分布式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/基础知识/">基础知识</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Laravel/" style="font-size: 10px;">Laravel</a> <a href="/tags/Redis/" style="font-size: 10px;">Redis</a> <a href="/tags/composer/" style="font-size: 10px;">composer</a> <a href="/tags/cpp/" style="font-size: 12.22px;">cpp</a> <a href="/tags/cpp-lib/" style="font-size: 10px;">cpp-lib</a> <a href="/tags/elasticsearch/" style="font-size: 11.11px;">elasticsearch</a> <a href="/tags/faiss/" style="font-size: 10px;">faiss</a> <a href="/tags/git/" style="font-size: 12.22px;">git</a> <a href="/tags/go-source-code/" style="font-size: 10px;">go.source.code</a> <a href="/tags/golang/" style="font-size: 16.67px;">golang</a> <a href="/tags/laravel/" style="font-size: 11.11px;">laravel</a> <a href="/tags/linux/" style="font-size: 14.44px;">linux</a> <a href="/tags/mac/" style="font-size: 13.33px;">mac</a> <a href="/tags/machine-learning/" style="font-size: 10px;">machine-learning</a> <a href="/tags/memcache/" style="font-size: 15.56px;">memcache</a> <a href="/tags/mysql/" style="font-size: 13.33px;">mysql</a> <a href="/tags/nginx/" style="font-size: 13.33px;">nginx</a> <a href="/tags/nosql/" style="font-size: 18.89px;">nosql</a> <a href="/tags/octave/" style="font-size: 10px;">octave</a> <a href="/tags/php/" style="font-size: 20px;">php</a> <a href="/tags/php源码学习/" style="font-size: 17.78px;">php源码学习</a> <a href="/tags/redis/" style="font-size: 12.22px;">redis</a> <a href="/tags/spark/" style="font-size: 12.22px;">spark</a> <a href="/tags/tcp/" style="font-size: 10px;">tcp</a> <a href="/tags/thrift/" style="font-size: 13.33px;">thrift</a> <a href="/tags/分布式/" style="font-size: 11.11px;">分布式</a> <a href="/tags/基础知识/" style="font-size: 15.56px;">基础知识</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">December 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">November 2015</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/11/19/分布式-CAP理论/">分布式-CAP理论</a>
          </li>
        
          <li>
            <a href="/2021/11/16/Spark-DataSource-Hive Tables/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/11/14/分布式-事务/">分布式-事务</a>
          </li>
        
          <li>
            <a href="/2019/04/29/golang继承/">golang继承</a>
          </li>
        
          <li>
            <a href="/2019/04/28/spark-Quick-Start/">spark quick start</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 Keything<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>