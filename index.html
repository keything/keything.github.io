<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Keything的日志</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Keything的日志">
<meta property="og:url" content="http://keything.github.io/index.html">
<meta property="og:site_name" content="Keything的日志">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Keything的日志">
  
    <link rel="alternate" href="/atom.xml" title="Keything的日志" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Keything的日志</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://keything.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-分布式-广播" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2021/11/24/分布式-广播/" class="article-date">
  <time datetime="2021-11-24T12:52:09.000Z" itemprop="datePublished">2021-11-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/11/24/分布式-广播/">分布式-广播</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>本文将介绍什么是广播、为什么有广播、广播有哪些分类、如何实现广播，广播有哪些应用。</p>
<h2 id="为什么要有广播？"><a href="#为什么要有广播？" class="headerlink" title="为什么要有广播？"></a>为什么要有广播？</h2><p>构建分布式的难点在于不可避免的并发以及提供全局控制，这可以通过<code>group communication</code>来降低难度。相比点对点通信，<code>group communication</code>原语提供了更高的保证。</p>
<p><code>broadcast protocols</code> 广播协议将消息发送给组内全部节点。组内成员可以是固定的，也可以加入或离开。</p>
<p>broadcast 是一个 <code>group communication</code> ，total order broadcast是一种broadcast。</p>
<p>当应用给组内全部节点发送消息时，可以使用一种算法去broadcast。</p>
<h2 id="broadcast和delivery理解"><a href="#broadcast和delivery理解" class="headerlink" title="broadcast和delivery理解"></a>broadcast和delivery理解</h2><p>broadcast和delivery 是更高维度的概念。send/receive是点对点的维度。<br><img src="//keything.github.io/2021/11/24/分布式-广播/receivingAndDelivering.jpg" alt=""></p>
<h2 id="广播的分类"><a href="#广播的分类" class="headerlink" title="广播的分类"></a>广播的分类</h2><p>total order broadcast protocol 要满足下面四个属性：</p>
<ul>
<li>validity (正确性)：如果一个正确的进程广播了一条消息，那么其他所有正确的进程都接收到这条消息</li>
<li>uniform agreement: 如果一个进程接收到消息m，那么所有正确的进程都接收到消息m</li>
<li>uniform integrity: 一个进程最多接收一次消息m</li>
<li>uniform total order: 如果进程p和q都接收到消息m和m’，当且仅当q接收消息m早于m’时，进程p接收消息m早于m’</li>
</ul>
<p>满足前三个属性的叫reliable broadcast。简要概括可靠广播：没有时间保证，所有消息都被没有错误的节点接收。</p>
<p>根据节点接收消息的顺序不同，可以得到几种广播：FIFO、causal、Total order Broadcast。</p>
<h3 id="FIFO-广播"><a href="#FIFO-广播" class="headerlink" title="FIFO 广播"></a>FIFO 广播</h3><p>定义：如果同一个节点发送的消息m1和m2，m1早于m2，那么接收上m1要早于m2。<br>如下图黑线所示。但可能出现节点C接收m2早于m1，那么符合FIFO（m1早于m3)，但不符合因果（因为节点B是接收m1后才广播m2）。<br><img src="//keything.github.io/2021/11/24/分布式-广播/FIFOBroadcast.jpg" alt=""></p>
<h3 id="Causal-广播"><a href="#Causal-广播" class="headerlink" title="Causal 广播"></a>Causal 广播</h3><p>定义：如果一个消息的广播 happens before 另外一个消息，那么所有节点的接收顺序也要保持这个顺序；如果两个消息并发，那么一个节点可以以任意接收。</p>
<p>如下图所示 broadcast(m1) -&gt; broadcast(m2) 并且 broadcast(m1) -&gt; broadcast(m3)，那么有效的顺序是:<br>(m1,m2,m3) 或 （m1,m3,m2)<br><img src="//keything.github.io/2021/11/24/分布式-广播/CausalBroadcast.jpg" alt=""></p>
<h3 id="Total-Order-广播，又叫atomic-broadcast-原子广播"><a href="#Total-Order-广播，又叫atomic-broadcast-原子广播" class="headerlink" title="Total Order 广播，又叫atomic broadcast 原子广播"></a>Total Order 广播，又叫atomic broadcast 原子广播</h3><p>定义：保证节点的一致性，确保所有节点以相同顺序接收消息。<br><img src="//keything.github.io/2021/11/24/分布式-广播/TotalOrderBroadcast.jpg" alt=""><br><img src="//keything.github.io/2021/11/24/分布式-广播/TotalOrderBroadcast2.jpg" alt=""></p>
<h2 id="广播算法"><a href="#广播算法" class="headerlink" title="广播算法"></a>广播算法</h2><p>广播算法可以分成两步骤：</p>
<ol>
<li>尽最大努力可靠的广播，通过重发丢失的消息</li>
<li>基于可靠广播，保证接收顺序</li>
</ol>
<h3 id="可靠广播"><a href="#可靠广播" class="headerlink" title="可靠广播"></a>可靠广播</h3><h4 id="尝试1：广播节点直接给其他节点发送消息"><a href="#尝试1：广播节点直接给其他节点发送消息" class="headerlink" title="尝试1：广播节点直接给其他节点发送消息"></a>尝试1：广播节点直接给其他节点发送消息</h4><p>当消息丢失 并且 发送节点崩溃时，将会有节点无法收到该消息。<br><img src="//keything.github.io/2021/11/24/分布式-广播/BroadcastAlgo.jpg" alt=""></p>
<p>为了改善这种情况，我们需要依赖其他节点的帮助。已经收到消息的节点，可以将其全部消息广播给其他节点。但是该算法并不高效：没有错误时，每个消息要发送O(n^2)次，每个节点至少收到n-1次消息。</p>
<p>有很多算法可以进行优化。比如 <a href="https://github.com/keything/paper_learning/blob/main/%5B1990%5DBroadcast-Protocols-for-Distributed-Systems.md" target="_blank" rel="noopener">Broadcast Protocols for Distributed Systems</a>中的trans protocol<br><img src="//keything.github.io/2021/11/24/分布式-广播/EagerReliableBroadcast.jpg" alt="">。当然最有名的是 <code>gossip protocols</code>。</p>
<p>基于可靠广播（使用eager reliable broadcast or gossip protocol），我们可以构建FIFO,causal,total order 广播。</p>
<h3 id="FIFO-broadcast-algo"><a href="#FIFO-broadcast-algo" class="headerlink" title="FIFO broadcast algo"></a>FIFO broadcast algo</h3><p><img src="//keything.github.io/2021/11/24/分布式-广播/FIFOBroadcastAlgo.jpg" alt=""></p>
<p>sendSeq 是发送节点自增的序号；delivered：一个发送节点是一个向量，记录接收节点已经接收的发送节点的数据。buffer：记录收到的节点，直到能够被delivere。</p>
<p>算法核心：对于每个发送，检查是否有预期seq匹配的，如果有则deliver m 给application；反之则等待消息接收。</p>
<h3 id="Causal-broadcast-algo"><a href="#Causal-broadcast-algo" class="headerlink" title="Causal broadcast algo"></a>Causal broadcast algo</h3><h3 id="Total-broadcast-algo"><a href="#Total-broadcast-algo" class="headerlink" title="Total broadcast algo"></a>Total broadcast algo</h3><p>采用共识算法</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="https://www.youtube.com/watch?v=x-D8iFU1d-o&amp;list=PLeKd45zvjcDFUEv_ohr_HdUFe97RItdiB&amp;index=11" target="_blank" rel="noopener">Dr. Martin Kleppmann 的Distributed Systems</a></li>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=DA32EDFFF7FE22C9B1B1CE7B36D2C6EC?doi=10.1.1.121.3113&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener">Broadcast Protocols for Distributed Systems</a></li>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.110.6701&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener">total order broadcast and multicase algorithms taxonomy and survey</a></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2021/11/24/分布式-广播/" data-id="ckwdj16s0005nsrnuic8dvww3" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/分布式/">分布式</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-分布式-CAP理论" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2021/11/19/分布式-CAP理论/" class="article-date">
  <time datetime="2021-11-19T05:49:15.000Z" itemprop="datePublished">2021-11-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/11/19/分布式-CAP理论/">分布式-CAP理论</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="CAP-理论"><a href="#CAP-理论" class="headerlink" title="CAP 理论"></a>CAP 理论</h1><p>CAP理论在互联网界有着广泛认知度，大家会将其作为衡量系统设计的标准。大家都能够清楚地讲出CAP理论：任何分布式系统在可用性、一致性、分区容错性方面，不能兼得，最多只能三选二，因此任何分布式系统设计只能在三者中进行不同取舍。</p>
<h2 id="1-CAP历史"><a href="#1-CAP历史" class="headerlink" title="1. CAP历史"></a>1. CAP历史</h2><p>2000年， Eric Brewer教授在PODC研讨会上提出一个猜想<a href="https://radlab.cs.berkeley.edu/people/fox/static/pubs/pdf/c18.pdf" target="_blank" rel="noopener">[1]</a>：一致性、可用性和分区容错性三者无法在分布式系统中被同时满足，并且最多只能满足其中两个！</p>
<p>这个猜想首次把一致性、可用性和分区容错三个因素提炼出来作为系统设计的重要特征，断言用此三者可以划分所有的分布式系统，并指明这三个特征之间的不可能性关系。</p>
<p>Brewer教授当时想象的分布式场景是webservice，一组webservice后台运行众多server，对service的读写会反应到后台的server集群，并且对CAP进行定义：</p>
<ul>
<li>Strong consistency: means single-copy ACID consistency; </li>
<li>High availability: 通过冗余（比如副本）提供高可用。如果特定数据消费者能够一直访问一些副本，那么数据被认为是高可用。</li>
<li>Partition-resilience: 当出现数据副本分区时，系统可以存活。</li>
</ul>
<p>Strong CAP Principle：Strong Consistency, High Availability, Partition-resilience：最多选择两个。</p>
<p>CAP猜想清晰表达在设计分布式应用的取舍，</p>
<ul>
<li>CA without P： 在没有网络分区的情况下，数据库提供分布式事务语义。</li>
<li>CP without A： 有网络分区下，在分区恢复之前，更多的ACID数据库的事务都会被阻塞，从而避免引入合并冲突，并带来不一致。</li>
<li>AP without C:  出现分区时，数据出现不一致。 通常，任何分布式数据问题可以通过基于过期的caching来获得AP，或多数选举获得PC（少数人群是不可用的）。</li>
</ul>
<p>Weak CAP Principle: 保证CAP的两个更强，那么意味着另外一个更弱。 </p>
<h2 id="2-CAP被上升为定理，"><a href="#2-CAP被上升为定理，" class="headerlink" title="2. CAP被上升为定理，"></a>2. CAP被上升为定理，</h2><p>2002年，Lynch与其他人<a href="https://users.ece.cmu.edu/~adrian/731-sp04/readings/GL-cap.pdf" target="_blank" rel="noopener">[2]</a>证明了Brewer猜想，从而把CAP上升为一个定理。但是只是证明了CAP三者不可能同时满足，并没有证明任意二者都可满足的问题，所以，该证明被认为是一个收窄的结果。</p>
<p>Lynch的证明采用反证法：如果三者同时满足，则因为P的存在，那么一定存在Server之间丢包，那么就不能保证C，证明简洁而严谨。</p>
<p>在该证明中，CAP进行更明确的声明：</p>
<ul>
<li>C：一致性被称为原子对象，任何读写都应该看起来是原子的，又叫线性化。写后面的读一定能读到前面写的内容。所有的读写请求都好像被全局排序。 </li>
<li>A：对任何非失败节点都应该在有限时间内给出响应。（请求的可终止性）</li>
<li>P：允许节点之间丢失任意多的消息，当网络分区发生时，节点之间的消息可能会完全丢失。</li>
</ul>
<h2 id="3-CAP的质疑"><a href="#3-CAP的质疑" class="headerlink" title="3. CAP的质疑"></a>3. CAP的质疑</h2><p>CAP理论考虑的场景很少，提供的是一个大的思路；不同论文/文章针对具体场景去质疑时，总能够指出CAP不合理的地方。 </p>
<p>但一个比较重要的地方就是不要真的只是进行三选二。比如在没有网络分区时，一致性和可用性也只能二选一。  </p>
<blockquote>
<p>以下是几篇论文和文章对CAP的质疑，有兴趣的可以了解一下</p>
</blockquote>
<h3 id="3-1-质疑1："><a href="#3-1-质疑1：" class="headerlink" title="3.1 质疑1："></a>3.1 质疑1：</h3><p>文章<a href="http://markburgess.org/blog_cap.html" target="_blank" rel="noopener">[8]</a>中对CAP有一系列描述，没太明白在说什么。 </p>
<h3 id="3-2-质疑2：-不要快速丢弃掉C"><a href="#3-2-质疑2：-不要快速丢弃掉C" class="headerlink" title="3.2 质疑2： 不要快速丢弃掉C"></a>3.2 质疑2： 不要快速丢弃掉C</h3><p>在<a href="https://cacm.acm.org/blogs/blog-cacm/83396-errors-in-database-systems-eventual-consistency-and-the-cap-theorem/fulltext" target="_blank" rel="noopener">[3]</a>中，其质疑的主张是：CAP必须放弃某一个目标。从错误中恢复有很多维度要考虑，该文章解释了很多种错误。结论是：不要轻易放弃C。因为分区容错在局域网中很少发生，在广域网中也有各种备选方案。 </p>
<h3 id="3-3-质疑3-构建不可避免模型避免CAP的复杂性"><a href="#3-3-质疑3-构建不可避免模型避免CAP的复杂性" class="headerlink" title="3.3 质疑3 构建不可避免模型避免CAP的复杂性"></a>3.3 质疑3 构建不可避免模型避免CAP的复杂性</h3><p>文章<a href="http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html" target="_blank" rel="noopener">[4]</a>的标题是锤死CAP。<br>作者认为CAP困境在于允许数据变更，每次变更都得数据同步，保持一致性，他认为数据是客观存在的，维护增删操作（译注：我个人认为是LSM log-structured message tree的理念）。<br>作者认为数据模型可以抽象为Query=Function(all data)，完全抛弃CAP中繁琐且模糊的定义。</p>
<p>我个人觉得：这篇文章只是换了一个角度来说明分布式系统，与CAP没啥关系。 </p>
<h2 id="4-对质疑的回应"><a href="#4-对质疑的回应" class="headerlink" title="4. 对质疑的回应"></a>4. 对质疑的回应</h2><p>面对大量的质疑，Brewer和Lynch进行重申，</p>
<p>Brewer在2012你那重申<a href="https://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed/" target="_blank" rel="noopener">[5]</a>:</p>
<ul>
<li>3选2这个表述是不准确的，在某些分区极少发生的情况下，三者能顺畅在一起配合。没有P时是CA，发生P时是PC或PA</li>
<li>CAP不仅仅发生在整个系统中，可能是发生在某个子系统或系统的某个阶段</li>
<li>CAP中每一个都是连续取值，而不是0-1关系。</li>
</ul>
<p>Lynch在10年后的2012年重写了论文<a href="http://groups.csail.mit.edu/tds/papers/Gilbert/Brewer2.pdf" target="_blank" rel="noopener">[9]</a>，该论文主要做了几件事：</p>
<ul>
<li>一致性场景不会引入用户agent，只发生在后台集群之内</li>
<li>引入了活性(liveness)和安全属性(safety)，在一个更抽象的概念下研究分布式系统，并认为CAP是活性与安全熟悉之间权衡的一个特例。其中的一致性属于liveness，可用性属于safety</li>
<li>把分区容错归结为一个对网络环境的陈述，而非之前一个独立条件。这实际上就是更加明确了概念</li>
<li>把CAP的研究推到一个更广阔的空间：网络存在同步、部分同步；一致性性的结果也从仅存在一个到存在N个（部分一致）；引入了通信周期round，并引用了其他论文，给出了为了保证N个一致性结果，至少需要通信的round数。也介绍了其他人的一些成果，这些成果分别都对CAP的某一个方面做出了特殊的贡献！</li>
</ul>
<p>其实Lynch论文主要做了两件事：</p>
<ul>
<li>缩小CAP适用的定义，消除质疑的场景；</li>
<li>展示了CAP在非单一一致性结果下的广阔研究成果！并顺便暗示CAP定理依旧正确！</li>
</ul>
<h2 id="5-很多系统既不是线性化-也不是CAP-Available-6"><a href="#5-很多系统既不是线性化-也不是CAP-Available-6" class="headerlink" title="5. 很多系统既不是线性化 也不是CAP-Available [6]"></a>5. 很多系统既不是线性化 也不是CAP-Available [6]</h2><p>基于严格的CAP定义，很多系统既不是线性化、也不是CAP-Available。</p>
<p>举例，考虑单主的多副本数据库，这是大多数关系型数据库创建副本的标准方式。在这种配置下，如果一个client与leader分离，那么它就不能再向数据库写入数据。即使可以从follower读取数据，但已经不能写入，这就不符合CAP-Avaible。当然这种配置常常被叫做“高可用性”。</p>
<p>如果单主复制不是CAP-Avaible，那么是不是CP呢？并不一定是。如果运行应用从follower读取数据，并且复制是异步的，那么副本可能会落后于leader，这时候读取就不是线性的，不符合CAP-consistent。</p>
<p>所以这些系统既不是CAP-consistent，也不是CAP-avaible。他们只是P。</p>
<p>以Zookeeper为例：</p>
<p>zookeeper使用consensus algorithm，所以人们常常将其看做是选择一致性高于可用性的例子，但事实上，zk默认是不提供线性读取。连接到数据库某个节点的client，读取的是该节点上的数据，即时最新的数据在其他节点。 默认Zookeeper不满足CAP中的C。</p>
<p>关于Zookeeper的Availablility？ </p>
<p>zk采用法定人数的方式实现共识。那么多数节点是可用的，而少数节点的集群是不能写入的，不符合ZK的CAP-available。 </p>
<h2 id="6-该如何看待CAP"><a href="#6-该如何看待CAP" class="headerlink" title="6. 该如何看待CAP"></a>6. 该如何看待CAP</h2><ul>
<li>当我们提到CAP的时候，首先我们指的是严格的CAP定义；</li>
<li>首先肯定的是，CAP并不适合再作为一个适应任何场景的定理，它的正确性更适合基于原子读写的NoSQL场景</li>
<li>无论如此，C、A、P三个概念始终存在于任何分布式系统，只是不同模型会有不同呈现；一个系统的不同子模块会有不同关系；<ul>
<li>在没有出现P（分区时），可以实现CA；</li>
<li>在出现P时，CA二选一，或者实现的是 C+HA</li>
</ul>
</li>
<li>当我们分析一个系统的时候，要从多个维度去分析，比如etcd是CP+HA <a href="https://medium.com/@ahadrana/understanding-etcd3-8784c4f61755" target="_blank" rel="noopener">[10]</a></li>
<li>有一个CAP理论的扩展叫PACELC理论</li>
</ul>
<h2 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h2><ol>
<li><a href="https://radlab.cs.berkeley.edu/people/fox/static/pubs/pdf/c18.pdf" target="_blank" rel="noopener">Harvest, Yield, and Scalable Tolerant Systems</a></li>
<li><a href="https://users.ece.cmu.edu/~adrian/731-sp04/readings/GL-cap.pdf" target="_blank" rel="noopener">Brewer’s Conjecture and the Feasibility of Consistent, Available, Partition-Tolerant Web</a></li>
<li><a href="https://cacm.acm.org/blogs/blog-cacm/83396-errors-in-database-systems-eventual-consistency-and-the-cap-theorem/fulltext" target="_blank" rel="noopener">Errors in Database Systems, Eventual Consistency, and the CAP Theorem</a></li>
<li><a href="http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html" target="_blank" rel="noopener">How to beat the CAP theorem</a></li>
<li><a href="https://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed/" target="_blank" rel="noopener">CAP Twelve Years Later: How the “Rules” Have Changed</a></li>
<li><a href="https://martin.kleppmann.com/2015/05/11/please-stop-calling-databases-cp-or-ap.html" target="_blank" rel="noopener">Please stop calling databases CP or AP</a></li>
<li><a href="https://blog.csdn.net/chen77716/article/details/30635543?spm=1001.2014.3001.5501" target="_blank" rel="noopener">CAP理论</a></li>
<li><a href="http://markburgess.org/blog_cap.html" target="_blank" rel="noopener">Deconstructing the `CAP theorem’ for CM and DevOps</a></li>
<li><a href="http://groups.csail.mit.edu/tds/papers/Gilbert/Brewer2.pdf" target="_blank" rel="noopener">Perspectives on the CAP Theorem</a></li>
<li><a href="https://medium.com/@ahadrana/understanding-etcd3-8784c4f61755" target="_blank" rel="noopener">understanding etcd3 (需要翻墙)</a></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2021/11/19/分布式-CAP理论/" data-id="ckwdj16ry005isrnuuoz5pvlb" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/分布式/">分布式</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Spark-DataSource-Hive Tables" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2021/11/16/Spark-DataSource-Hive Tables/" class="article-date">
  <time datetime="2021-11-16T09:45:21.249Z" itemprop="datePublished">2021-11-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2021/11/16/Spark-DataSource-Hive Tables/" data-id="ckwdj16nu0000srnu5maq0h60" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-分布式-事务" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2021/11/14/分布式-事务/" class="article-date">
  <time datetime="2021-11-14T02:34:03.000Z" itemprop="datePublished">2021-11-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/11/14/分布式-事务/">分布式-事务</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文是《数据密集型应用系统设计》（英文：Designing Data-Intensive Applications) 第7章学习总结。</p>
<p>在总结之前，提问几个问题：</p>
<ol>
<li>什么是事务?</li>
<li>为什么引入事务</li>
<li>事务中最核心的问题是什么？</li>
<li>事务中隔离级别有哪些级别，级别划分依据是什么？</li>
<li>隔离级别解决了哪些问题，哪些没有解决</li>
<li>如何实现这些隔离级别</li>
</ol>
<h2 id="一、事务"><a href="#一、事务" class="headerlink" title="一、事务"></a>一、事务</h2><h3 id="什么是事务"><a href="#什么是事务" class="headerlink" title="什么是事务"></a>什么是事务</h3><p>在应用程序中，将一组数据库的读写组成一个逻辑操作单元；即事务中所有读写是一个执行的整体，整个事务要么成功（提交），要么失败（中止或回滚）。如果失败，应用程序可以安全地重试。</p>
<h3 id="为什么引入事务"><a href="#为什么引入事务" class="headerlink" title="为什么引入事务"></a>为什么引入事务</h3><p>简化应用层的编程模型：当一组读写中部分写入成功，部分写入失败时，我们需要将成功的进行回滚；如果数据库不引入事务，就需要业务层自己处理。 </p>
<p>如何判断是否需要事务？</p>
<blockquote>
<p>我们需要确切地理解事务能够提供哪些安全性保证，背后的代价又是什么。 </p>
</blockquote>
<h3 id="事务提供的安全性保证"><a href="#事务提供的安全性保证" class="headerlink" title="事务提供的安全性保证"></a>事务提供的安全性保证</h3><p>事务提供的安全性保证即大家熟悉的ACID。</p>
<ul>
<li>Atomic（原子性）：执行要么全部成功，要么全部失败。在出错时中止事务，并将部分完成的写入全部丢弃。 </li>
<li>Consistency(一致性）：这儿的一致性是符合数据的约束条件（比如数据x=y,x+y=100等)</li>
<li>Isolation（隔离）：意味着并发执行的多个事务相互隔离，他们不能互相交叉。经典数据库教材中把隔离定义为可串行化。</li>
<li>Duration（持久化）：数据持久化</li>
</ul>
<p>其中AID是数据库自身属性，C是应用层属性，AID来保证C。</p>
<h2 id="二、隔离级别"><a href="#二、隔离级别" class="headerlink" title="二、隔离级别"></a>二、隔离级别</h2><h3 id="2-1-什么时候需要隔离？"><a href="#2-1-什么时候需要隔离？" class="headerlink" title="2.1 什么时候需要隔离？"></a>2.1 什么时候需要隔离？</h3><p>如果两个事务操作的是不同的数据，即不存在数据依赖关系，那么就可以安全地并行。</p>
<p>只有出现某个事务修改数据而另外一个事务同时读取该数据，或者两个事务同时修改相同数据时，才会引起并发问题。</p>
<h3 id="2-2-隔离级别的定义"><a href="#2-2-隔离级别的定义" class="headerlink" title="2.2 隔离级别的定义"></a>2.2 隔离级别的定义</h3><p>ANSI/ISO SQL-92中定义了四种隔离级别Read-Commited, Repeatable Read, Snapshot Isolation, Seriable。这些隔离级别是通过经典的序列化定义和三种被禁止的子序列来定义的。三种被禁止的子序列是Dirty Read, Non-repeatable Read 和 phantom(幻象）。</p>
<blockquote>
<p>通俗来讲，就是禁止了哪些问题就达到了某个隔离级别；隔离级别也都是与特定的锁有对应关系的</p>
</blockquote>
<p>隔离级别也是与lock有关的。</p>
<h3 id="2-3-异常现象（异常子序列）"><a href="#2-3-异常现象（异常子序列）" class="headerlink" title="2.3 异常现象（异常子序列）"></a>2.3 异常现象（异常子序列）</h3><p>这些异常现象将会用如下格式进行详细描述：</p>
<ul>
<li>问题的文字描述</li>
<li>问题的序列化表示</li>
<li>问题的例子</li>
<li>问题的解决方案</li>
</ul>
<p>关于锁的解释</p>
<ol>
<li>long-duration vs short duration<ul>
<li>长期锁是在加锁以后，直到事务结束或回滚才释放锁</li>
<li>短期锁是在动作结束以后，就立即释放锁</li>
</ul>
</li>
<li><p>predict  vs 行锁</p>
<ul>
<li>predict lock是针对一个查询条件加锁</li>
<li>行锁是针对特定一行记录加锁</li>
</ul>
</li>
</ol>
<h4 id="脏写-Dirty-Write-P0"><a href="#脏写-Dirty-Write-P0" class="headerlink" title="脏写 Dirty Write P0"></a>脏写 Dirty Write P0</h4><ol>
<li>问题的文字描述：一个正在进行的事务覆盖了另外一个事务尚未提交的写入。</li>
<li>问题的序列化表示：W1(x)…W2(x) … (c1 or a1)</li>
<li>问题的解决办法：对写入加一个long-duration write lock。</li>
<li>说明：<ul>
<li>Dirty write是ANSI/ISO SQL-92中没有提到的，但是需要避免，是基础。</li>
<li>如果有脏写，那么会没有办法回滚，也可能影响数据约束（x=y or x+y=100)</li>
</ul>
</li>
<li>举例：Suppose T1 writes x=y=1 and T2 writes x=y=2, the following history violates the integrity constraint.</li>
</ol>
<p><img src="https://blog.acolyer.org/wp-content/uploads/2016/02/dirty-write.png" alt=""></p>
<h4 id="脏读-Dirty-Read-P1"><a href="#脏读-Dirty-Read-P1" class="headerlink" title="脏读 Dirty Read P1"></a>脏读 Dirty Read P1</h4><ol>
<li>问题的文字描述：一个正在进行的事务读取了另外一个事务未提交的写入。</li>
<li>问题的序列化表示：W1(x)..R2(x) ..(c1 or a1)</li>
<li>问题的解决办法：加入一个short-duration read lock。<ul>
<li>写是long-duration write lock, 读是short-duration read lock，当正在发生写入的事务占有锁时，读取的事务因为没有办法获得读锁，只能等待。 </li>
<li>注明：<a href="http://arxiv.org/pdf/cs/0701157.pdf" target="_blank" rel="noopener">1</a>中使用读锁来实现，但是在最新的数据库中数据库维护新旧两个取值，事务提交之前读取旧值；仅当写事务提交以后，才会切换到读取新值。</li>
</ul>
</li>
<li>说明：<ul>
<li>解决该问题的隔离级别就是 Read-Commited（读-提交） 隔离级别</li>
</ul>
</li>
<li>举例：<ul>
<li>序列化：H1: r1[x=50]w1[x=10]r2[x=10]r2[y=50]c2 r1[y=50]w1[y=90]c1</li>
<li>如下图所示 t2中 x+y=60，其中x=10是脏读，<img src="//keything.github.io/2021/11/14/分布式-事务/dirty read.jpeg" alt=""></li>
</ul>
</li>
</ol>
<h4 id="不可重复读-unrepeatable-read-P2"><a href="#不可重复读-unrepeatable-read-P2" class="headerlink" title="不可重复读 unrepeatable-read P2"></a>不可重复读 unrepeatable-read P2</h4><ol>
<li>问题的文字描述：事务在不同的时间点看到不同值。事务T2修改了之前事务T1读过的数据，不管T1、T2是提交还是回滚，就认为是nonrepeatable-read</li>
<li>问题的序列化表示：R1(x)..W2(x)..(c1 or a1)</li>
<li>问题的解决办法：snapshot isolation，多版本</li>
<li>说明：不可重复读实际是 读倾斜的x等于y的一个特例</li>
<li>举例：因为不可重复读可以看做是读倾斜x等于y的一个特例，可以去看 读倾斜的例子。</li>
</ol>
<h4 id="幻象-phantom-P3"><a href="#幻象-phantom-P3" class="headerlink" title="幻象 phantom P3"></a>幻象 phantom P3</h4><ol>
<li><p>问题的文字描述：</p>
<p> 事务T1读取一组数据集合满足条件<search condition="">。事务T2创建了满足T1中<search condition="">的数据集合并提交，那么T1重复读取<search condition="">时，将会获取到跟之前不同的数据</search></search></search></p>
</li>
<li><p>问题的序列化表示：R1(P)… W2(y in P)…(c1 or a1)</p>
</li>
<li>问题的解决办法：采用区间范围锁 index-range lock，又叫next-key lock</li>
<li>说明：<ul>
<li>Nonrepeatable和幻象的区别 一个单个对象，一个是多个对象</li>
</ul>
</li>
</ol>
<h5 id="严格意义的幻象-A3"><a href="#严格意义的幻象-A3" class="headerlink" title="严格意义的幻象 A3"></a>严格意义的幻象 A3</h5><ol>
<li>问题的序列化表示：R1(p)..W2(y in p)..c2..r1(p)…c1</li>
<li>与P3相比更加严格，有一次T1的读取操作。</li>
<li>问题解决办法：使用snapshot isolation即可解决</li>
</ol>
<h4 id="更新丢失-Losst-update-P4"><a href="#更新丢失-Losst-update-P4" class="headerlink" title="更新丢失 Losst update P4"></a>更新丢失 Losst update P4</h4><ol>
<li>问题的文字描述：事务T2对X的修改被事务T1的修改覆盖。之后事务T1提交，从外界看来，T1对X的修改丢失</li>
<li>问题的序列化表示：R1(x)..W2(x)..W1(x)..C1</li>
<li>问题的解决办法：snapshot isolation，多版本</li>
<li>举例：<ul>
<li>序列化是 H4: r1[x=100]r2[x=100]w2[x=120 c2 w1 [x=130] c1</li>
<li>预期是从100经过+20，+30，最后取值是150；实际是130。如图所示 <img src="//keything.github.io/2021/11/14/分布式-事务/lost update.jpeg" alt=""></li>
</ul>
</li>
</ol>
<h4 id="更新丢失-Cursor-Lost-update-P4C"><a href="#更新丢失-Cursor-Lost-update-P4C" class="headerlink" title="更新丢失 Cursor Lost update P4C"></a>更新丢失 Cursor Lost update P4C</h4><p>P4C is a variation of the Lost Update phenomenon that involves a SQL cursor. In the history below, let rc(x) represent a read of the data item x under the cursor, and wc(x) a write of the data item x under the cursor. If we allow another transaction T2 to write to x in between the read-cursor and write-cursor actions of T1, then its update will be lost.</p>
<p>序列化表示：P4C: rc1[x]..w2[x] ..w1[x] ..c1<br><img src="https://blog.acolyer.org/wp-content/uploads/2016/02/cursor-lost-update.png" alt=""></p>
<h3 id="数据不一致-data-item-constraint-violation-A5"><a href="#数据不一致-data-item-constraint-violation-A5" class="headerlink" title="数据不一致 data item constraint violation A5"></a>数据不一致 data item constraint violation A5</h3><ol>
<li>问题的文字描述：两个数据X和Y满足某些限制，可能有以下异常情况出现：<ul>
<li>A5A Read Skew: 假设T1读取X，之后T2更新x和y到了新的取值，并提交；之后T1读取y，则x和y的限制被打破。</li>
<li>A5B Write Skew: 假设T1读取X和Y，之后T2读取X和Y，并写入X，然后提交；之后T1 写入Y，那么存在X和Y的限制被打破的可能</li>
</ul>
</li>
</ol>
<h4 id="A5A-Read-Skew"><a href="#A5A-Read-Skew" class="headerlink" title="A5A Read Skew:"></a>A5A Read Skew:</h4><ol>
<li>序列化表示：A5A: R1(x)..W2(x)..W2(y)..C2 …R1(y) .. (c1 or a1)</li>
<li>举例：<pre><code>以银行转账为例，初始化x=y=50，从x转走40到y，最终预期是x=10,y=90。
出现脏读时，其读取数据是 r1[x=5]r2[x=50]w2[x=10]r2[y=50]w2[y=90]c2r1[y=90]c1
数据如图所示，t1中x+y=140不满足100的限制。 ![](分布式-事务/repeatable read.jpeg)
</code></pre></li>
</ol>
<h4 id="A5B-Write-Skew"><a href="#A5B-Write-Skew" class="headerlink" title="A5B Write Skew:"></a>A5B Write Skew:</h4><ol>
<li>序列化表示：A5B：R1(x)..R2(y)..W1(y)..W2(x)..(c1 and c2 occur)</li>
<li>举例：</li>
</ol>
<p><img src="https://blog.acolyer.org/wp-content/uploads/2016/02/write-skew1.png" alt=""></p>
<h3 id="2-4-隔离级别"><a href="#2-4-隔离级别" class="headerlink" title="2.4 隔离级别"></a>2.4 隔离级别</h3><p>可以通过刻画他们禁止的异常情况来刻画隔离级别</p>
<p><img src="//keything.github.io/2021/11/14/分布式-事务/isolation types.jpeg" alt=""></p>
<p>他们之间的关系如下图所示 <img src="//keything.github.io/2021/11/14/分布式-事务/isolation levels and their relationship.jpeg" alt=""></p>
<p>我们可以通过他们允许的非序列化历史来比较隔离级别：</p>
<ul>
<li>L1 is weaker than L2 if L1 permits non-serializable histories that L2 does not, and every non-serializable history under L2 is also a non-serializable history under L1. We write L1 &lt;&lt; L2.</li>
<li>L1 and L2 are equivalent if the sets of non-serializable histories permitted by them both are identical. We write L1 == L2</li>
<li>L1 and L2 may also be incomparable. If L1 permits a non-serializable history that L2 does not, and vice-versa, then L1 is not weaker than L2, but L2 is also not weaker than L1. We write L1 &lt;&gt; L2.</li>
</ul>
<h4 id="结论1"><a href="#结论1" class="headerlink" title="结论1:"></a>结论1:</h4><p>我们可以得到 </p>
<blockquote>
<p>Degree 0 (everything goes) &lt;&lt; Read Uncommitted &lt;&lt; Read Committed &lt;&lt; Cursor Stability &lt;&lt; Repeatable Read &lt;&lt; Serializable.</p>
</blockquote>
<p>重点解释一下 Cursor Stability，Cursor Stability是扩展Read Commited锁行为。//TODO 待补充</p>
<h4 id="结论2："><a href="#结论2：" class="headerlink" title="结论2："></a>结论2：</h4><blockquote>
<p>Read commited &lt;&lt; snapshot isolation</p>
</blockquote>
<blockquote>
<p>ANOMALY Serializable &lt;&lt; Snapshot isolation</p>
</blockquote>
<blockquote>
<p>repeatable read &lt;&gt;  snapshot isolation 这两个是不可比较的。</p>
</blockquote>
<p>许多应用通过使用cursor stability 或 oracle’s read consistency isolation 来避免锁竞争。对于这些应用而言，使用Snapshot Isolation会更好：</p>
<ul>
<li>避免lost update</li>
<li>严格意义的幻象(如上面所说明的A3，但不能定义更广的P3）</li>
<li>从不阻塞只读的事务，读取不会阻塞更新</li>
</ul>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ol>
<li>Hal Berenson, Philip A. Bernstein, Jim N. Gray, et al.: “<a href="http://research.microsoft.com/pubs/69541/tr-95-51.pdf" target="_blank" rel="noopener">A Critique of ANSI SQL Isolation Levels,</a>” at ACM International Conference on Management of Data (SIG‐ MOD), May 1995</li>
<li><a href="https://blog.acolyer.org/2016/02/24/a-critique-of-ansi-sql-isolation-levels/" target="_blank" rel="noopener">A Critique of ANSI SQL Isolation Levels 解释</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/187597966" target="_blank" rel="noopener">A Critique of ANSI SQL Isolation Levels 阅读笔记</a></li>
<li>数据密集型应用系统设计 chapter 7 事务</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2021/11/14/分布式-事务/" data-id="ckwdj16rz005ksrnu61h72cw4" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/分布式/">分布式</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-golang继承" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/04/29/golang继承/" class="article-date">
  <time datetime="2019-04-29T02:52:38.000Z" itemprop="datePublished">2019-04-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/29/golang继承/">golang继承</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>项目中已经经常使用golang继承，现在总结一下，主要摘在<a href="https://hackthology.com/golangzhong-de-mian-xiang-dui-xiang-ji-cheng.html" target="_blank" rel="noopener">Golang中的面向对象继承</a></p>
<p>总结如下：</p>
<ol>
<li>golang使用组合，可以将两个结构体简单组合形成一个新的数据类型</li>
<li>可以通过匿名嵌入方式实现继承，从而共享代码和数据</li>
<li><p>匿名嵌入有三种方式</p>
<ul>
<li>接口类型</li>
<li>结构体实例</li>
<li>结构体实例指针</li>
</ul>
<p>接口类型更加灵活，只要实现这个接口的方法都可以进行赋值。</p>
<p>继承自其它结构体的struct类型可以直接访问父类结构体字段/方法</p>
</li>
<li><p>嵌入继承机制的局限</p>
<p>Golang从根本上阻止了抽象方法的使用。</p>
</li>
<li><p>多态性</p>
<p>golang不支持多态，即不能用子类替换父类。<br>但是golang支持接口类型的多态机制，只要结构体实现了接口的方法就可以进行赋值。</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2019/04/29/golang继承/" data-id="ckwdj16qf002isrnuy36d9us1" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/golang/">golang</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-spark-Quick-Start" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/04/28/spark-Quick-Start/" class="article-date">
  <time datetime="2019-04-28T11:52:36.000Z" itemprop="datePublished">2019-04-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/28/spark-Quick-Start/">spark quick start</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>注意， Spark2.0 之前的版本，Spark的主要编程接口是RDD(Resilient Distributed Dataset)。2.0以后的版本，主要编程接口替换为Dataset。当然了RDD接口依然支持，可以从<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener">RDD programming guide</a>。但是，我们强烈建议你切换到Dataset，比RDD有更好的性能。 关于Dataset可以从<a href="https://spark.apache.org/docs/latest/sql-programming-guide.html" target="_blank" rel="noopener">SQL programming guide</a>获得更多细节。</p>
<h3 id="使用SparkShell进行交互分析"><a href="#使用SparkShell进行交互分析" class="headerlink" title="使用SparkShell进行交互分析"></a>使用SparkShell进行交互分析</h3><h4 id="基础内容"><a href="#基础内容" class="headerlink" title="基础内容"></a>基础内容</h4><p>启动 ./bin/spark-shell</p>
<p>基本执行：</p>
<pre><code>val textFile = spark.read.textFile(&quot;README.md&quot;)
textFile.count() // Number of items in this Dataset
textFile.first() // first item in this Dataset
</code></pre><p>将一个Dataset转换为新的一个。 调用<code>filter</code>返回新的Dataset，是原始文件的一个子集</p>
<pre><code>val linesWithSpark = textFile.filter(t =&gt; t.contains(&quot;Spark&quot;))
</code></pre><h4 id="这儿有个疑问，如何打印出dataset中内容？？"><a href="#这儿有个疑问，如何打印出dataset中内容？？" class="headerlink" title="这儿有个疑问，如何打印出dataset中内容？？"></a>这儿有个疑问，如何打印出dataset中内容？？</h4><h4 id="更多的Dataset的操作"><a href="#更多的Dataset的操作" class="headerlink" title="更多的Dataset的操作"></a>更多的Dataset的操作</h4><p>Dataset的actions和transformation 可以用于更多的复杂运算。</p>
<pre><code>textFile.map(line =&gt; line.split(&quot; &quot;).size).reduce((a,b) =&gt; if (a &gt; b) a else b)
res4: Long = 15
</code></pre><p>map和reduce的参数都是scala的匿名函数，还可以使用scala/java 库。例如 可以使用<code>Math.max()</code>函数。</p>
<pre><code>import java.lang.Math
textFile.map(line =&gt; line.split(&quot; &quot;).size).reduce((a, b) =&gt; Math.max(a,b))
</code></pre><p>一个通用的数据处理流程是MapReduce。Spark可以很容易的实现MapReduce流。 </p>
<pre><code>val wordCounts = textFile.map(line =&gt; line.split(&quot; &quot;)).groupByKey(identity).count()
</code></pre><h4 id="Caching"><a href="#Caching" class="headerlink" title="Caching"></a>Caching</h4><p>spark支持将dataset写入cluster-wide in-memory cache。<br>当数据重复获取时，这还是很有用的。 </p>
<h4 id="Self-Contained-Application"><a href="#Self-Contained-Application" class="headerlink" title="Self-Contained Application"></a>Self-Contained Application</h4><p>使用SparkAPI创建一个self-contained应用。</p>
<pre><code>import org.apache.spark.sql.SparkSession

object SimpleApp {
  def main(args: Array[String]) {
    val logFile = &quot;README.md&quot; // Should be some file on your system
    val spark = SparkSession.builder.appName(&quot;Simple Application&quot;).getOrCreate()
    val logData = spark.read.textFile(logFile).cache()
    val numAs = logData.filter(line =&gt; line.contains(&quot;a&quot;)).count()
    val numBs = logData.filter(line =&gt; line.contains(&quot;b&quot;)).count()
    println(s&quot;Lines with a: $numAs, Lines with b: $numBs&quot;)
    spark.stop()
  }
}
</code></pre><p>其中<code>SparkSession.builder</code>构造一个[[SparkSession]]，使用设置application name，最后调用<code>getOrCreate</code>获取[[SparkSession]]实例。</p>
<p>也可以使用maven来进行包管理。 </p>
<p>目录结构：</p>
<pre><code>./pom.xml
./src
./src/main
./src/main/scala
./src/main/scala/didi
./src/main/scala/didi/map
./src/main/scala/didi/map/pointsys
./src/main/scala/didi/map/pointsys/App.scala
./src/test
./src/test/scala
./src/test/scala/didi
./src/test/scala/didi/map
./src/test/scala/didi/map/pointsys
</code></pre><p>App.scala内容：</p>
<pre><code>package didi.map.pointsys

import org.apache.spark.sql.SparkSession
object MyFunctions {
  def func1(s: String): String = {
    s.concat(&quot;yankai&quot;)
  }
}
// spark-submit --class=&quot;didi.map.pointsys.SimpleApp&quot; parking-user-profile-1.0-SNAPSHOT.jar
object SimpleApp {
  def main(args: Array[String]) {
    val logFile = &quot;README.md&quot; // Should be some file on your system
    val ss = SparkSession.builder().appName(&quot;Simple Application&quot;).enableHiveSupport().getOrCreate()
    val logData = ss.read.textFile(logFile)
    //val pairs = logData.map(s =&gt; (s, 1))

    val numAs = logData.filter(line =&gt; line.contains(&quot;a&quot;)).count()
    val numBs = logData.filter(line =&gt; line.contains(&quot;b&quot;)).count()
    println(s&quot;Lines with a: $numAs, Lines with b: $numBs&quot;)
    ss.stop()
  }
}
</code></pre><p>pom.xml</p>
<pre><code>&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;
  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
  &lt;groupId&gt;didi.map.pointsys&lt;/groupId&gt;
  &lt;artifactId&gt;parking-user-profile&lt;/artifactId&gt;
  &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
  &lt;inceptionYear&gt;2008&lt;/inceptionYear&gt;
  &lt;properties&gt;
    &lt;encoding&gt;UTF-8&lt;/encoding&gt;
    &lt;scala.binary.version&gt;2.11&lt;/scala.binary.version&gt;
    &lt;scala.major.version&gt;2.11&lt;/scala.major.version&gt;
    &lt;deploy.scala.version&gt;2.11&lt;/deploy.scala.version&gt;
    &lt;scala.version&gt;2.11.8&lt;/scala.version&gt;
    &lt;scala.compat.version&gt;2.11&lt;/scala.compat.version&gt;
    &lt;spark.version&gt;2.2.0&lt;/spark.version&gt;
  &lt;/properties&gt;

  &lt;dependencies&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;junit&lt;/groupId&gt;
      &lt;artifactId&gt;junit&lt;/artifactId&gt;
      &lt;version&gt;4.12&lt;/version&gt;
      &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
      &lt;artifactId&gt;spark-core_2.11&lt;/artifactId&gt;
      &lt;version&gt;2.3.0&lt;/version&gt;
      &lt;scope&gt;provided&lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
      &lt;artifactId&gt;spark-sql_2.11&lt;/artifactId&gt;
      &lt;version&gt;2.3.0&lt;/version&gt;
      &lt;scope&gt;provided&lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
      &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;
      &lt;version&gt;2.7.2&lt;/version&gt;
      &lt;scope&gt;provided&lt;/scope&gt;
    &lt;/dependency&gt;

  &lt;/dependencies&gt;
  &lt;build&gt;
    &lt;sourceDirectory&gt;src/main/scala&lt;/sourceDirectory&gt;
    &lt;testSourceDirectory&gt;src/test/scala&lt;/testSourceDirectory&gt;
    &lt;plugins&gt;
      &lt;!-- bind the maven-assembly-plugin to the package phase this will create
          a jar file without the storm dependencies suitable for deployment to a cluster. --&gt;

      &lt;plugin&gt;
        &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt;
        &lt;artifactId&gt;scala-maven-plugin&lt;/artifactId&gt;
        &lt;version&gt;3.2.0&lt;/version&gt;
        &lt;executions&gt;
          &lt;execution&gt;
            &lt;goals&gt;
              &lt;goal&gt;compile&lt;/goal&gt;
              &lt;goal&gt;testCompile&lt;/goal&gt;
            &lt;/goals&gt;
          &lt;/execution&gt;
        &lt;/executions&gt;
        &lt;configuration&gt;
          &lt;scalaVersion&gt;${scala.version}&lt;/scalaVersion&gt;
        &lt;/configuration&gt;
      &lt;/plugin&gt;

      &lt;plugin&gt;
        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
        &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;
        &lt;version&gt;2.2-beta-5&lt;/version&gt;
        &lt;configuration&gt;
          &lt;descriptorRefs&gt;
            &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;
          &lt;/descriptorRefs&gt;
        &lt;/configuration&gt;
        &lt;executions&gt;
          &lt;execution&gt;
            &lt;phase&gt;package&lt;/phase&gt;
            &lt;goals&gt;
              &lt;goal&gt;single&lt;/goal&gt;
            &lt;/goals&gt;
          &lt;/execution&gt;
        &lt;/executions&gt;
      &lt;/plugin&gt;

      &lt;plugin&gt;
        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
        &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
        &lt;version&gt;3.5.1&lt;/version&gt;
        &lt;configuration&gt;
          &lt;source&gt;1.8&lt;/source&gt;
          &lt;target&gt;1.8&lt;/target&gt;
        &lt;/configuration&gt;
      &lt;/plugin&gt;
      &lt;!-- disable surefire --&gt;
      &lt;plugin&gt;
        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
        &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;
        &lt;version&gt;2.7&lt;/version&gt;
        &lt;configuration&gt;
          &lt;skipTests&gt;true&lt;/skipTests&gt;
        &lt;/configuration&gt;
      &lt;/plugin&gt;
      &lt;!-- enable scalatest --&gt;
      &lt;!-- &lt;plugin&gt;
        &lt;groupId&gt;org.scalatest&lt;/groupId&gt;
        &lt;artifactId&gt;scalatest-maven-plugin&lt;/artifactId&gt;
        &lt;version&gt;1.0&lt;/version&gt;
        &lt;configuration&gt;
          &lt;reportsDirectory&gt;${project.build.directory}/surefire-reports&lt;/reportsDirectory&gt;
          &lt;junitxml&gt;.&lt;/junitxml&gt;
          &lt;filereports&gt;WDF TestSuite.txt&lt;/filereports&gt;
        &lt;/configuration&gt;
        &lt;executions&gt;
          &lt;execution&gt;
            &lt;id&gt;test&lt;/id&gt;
            &lt;goals&gt;
              &lt;goal&gt;test&lt;/goal&gt;
            &lt;/goals&gt;
          &lt;/execution&gt;
        &lt;/executions&gt;
      &lt;/plugin&gt;
      --&gt;
    &lt;/plugins&gt;

    &lt;resources&gt;
      &lt;resource&gt;
        &lt;directory&gt;src/main/resources&lt;/directory&gt;
      &lt;/resource&gt;
    &lt;/resources&gt;

  &lt;/build&gt;
&lt;/project&gt;
</code></pre><p>在target目录下会生成jar文件，使用spark-submit进行提交。</p>
<pre><code>spark-submit --class=&quot;didi.map.pointsys.SimpleApp&quot; parking-user-profile-1.0-SNAPSHOT.jar
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2019/04/28/spark-Quick-Start/" data-id="ckwdj16rj004gsrnuqw53d6f2" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/">spark</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-golang-包导入" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/20/golang-包导入/" class="article-date">
  <time datetime="2019-03-20T11:52:36.000Z" itemprop="datePublished">2019-03-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/20/golang-包导入/">golang包导入</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="golang包导入"><a href="#golang包导入" class="headerlink" title="golang包导入"></a>golang包导入</h2><p>go源代码是按package方式组织，再通过import引入使用。</p>
<h3 id="工作目录"><a href="#工作目录" class="headerlink" title="工作目录"></a>工作目录</h3><p>在Go中代码保持在称之为workspace的系统文件夹中。这个工作目录有三个根目录：</p>
<ul>
<li>bin：包含可执行文件</li>
<li>pkg：包含不同操作系统架构的包二进制文件。</li>
<li>src：包含按包方式组织的源代码</li>
</ul>
<p>其中bin和pkg文件夹是在调用go命令安装和编译源代码时自动生成。</p>
<p>必须让Go知道工作目录的位置，这样才能知道包的具体位置。 通过设置环境变量GOPATH来指定。 </p>
<h3 id="导入包"><a href="#导入包" class="headerlink" title="导入包"></a>导入包</h3><ol>
<li><p>$GOPATH/src/importpackage/lib/lib.go</p>
<pre><code>package lib

import &quot;fmt&quot;

func SayHello() {
    fmt.Println(&quot;Hello,I&apos;m in myLib :) &quot;)
}
</code></pre></li>
<li><p>$GOPATH/src/importpackage/app/main.go</p>
<pre><code>package main

import &quot;importpackage/lib&quot;

func main() {
    lib.SayHello()
}
</code></pre></li>
<li><p>目录结构：</p>
<pre><code>.
└── src
    └── importpackage
        ├── app
        │   └── main.go
        └── lib
            └── lib.go
</code></pre><p> go build -o main src/importpackage/app/main.go             </p>
</li>
</ol>
<h3 id="导入包的多种方式"><a href="#导入包的多种方式" class="headerlink" title="导入包的多种方式"></a>导入包的多种方式</h3><ul>
<li>代码统一存储在工作目录下</li>
<li>工作目录里面有多个包，不同包按目录组织，包下面由多个代码文件组成。</li>
<li>导入包时按包的唯一路径进行导入，导入的包默认是必须要使用，如果不使用则编译失败，需要移除，减少不必要代码的引入，当然还有其他使用场景。默认情况下，我们使用文件名做为包名，方便理解。不同包组织不同的功能实现，方便理解。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2019/03/20/golang-包导入/" data-id="ckwdj16qc002csrnuaq4jsirq" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/golang/">golang</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-golang-与zookeeper交互" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/02/golang-与zookeeper交互/" class="article-date">
  <time datetime="2019-03-02T09:20:45.000Z" itemprop="datePublished">2019-03-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/02/golang-与zookeeper交互/">golang-与zookeeper交互</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>golang与zookeeper交互使用<a href="https://github.com/samuel/go-zookeeper/blob/master/examples/basic.go" target="_blank" rel="noopener">package github.com/samuel/go-zookeeper/zk</a></p>
<p>Connect函数定义</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2019/03/02/golang-与zookeeper交互/" data-id="ckwdj16qb002bsrnu4qllm7cg" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/golang/">golang</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-golang-面向对象编程" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/02/golang-面向对象编程/" class="article-date">
  <time datetime="2019-03-02T07:08:34.000Z" itemprop="datePublished">2019-03-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/02/golang-面向对象编程/">golang-面向对象编程</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>理解golang面向对象</p>
<p>面向对象编程的三个核心是：封装、继承、多态。</p>
<ol>
<li><p>封装(encapsulation)</p>
<p> 封装就是将抽象得到的数据和行为（或功能）相结合，形成一个有机的整体，也就是将数据与操作数据的源代码进行有机的结合，形成“类”，其中数据和函数都是类的成员。</p>
<p> 封装的目的是增强安全性和简化编程，使用者不必了解具体的实现细节，而只是要通过 外部接口，一特定的访问权限来使用类的成员。<br> 即不直接暴露数据，而暴露的是接口.</p>
<p> go封装是package层面的。小写开头的Names只能在包内可见。在一个private package可以隐藏所有东西，并只暴露特定类型、接口、工厂函数。</p>
</li>
</ol>
<ol start="2">
<li><p>继承</p>
<p> 继承是指一个对象直接使用另一对象的属性和方法。事实上，我们遇到的很多实体都有继承的含义。例如，若把汽车看成一个实体，它可以分成多个子实体，如：卡车、公共汽车等。这些子实体都具有汽车的特性，因此，汽车是它们的“父亲”，而这些子实体则是汽车的“孩子”。</p>
</li>
</ol>
<pre><code>现代语言认为实现继承更好的方式是组合(composition)。go采用这种理念，并且没有任何等级内容(hierarchy)。 这允许你使用组合来共享实现的细节。go是通过嵌入(embedding)的方式来实现匿名组合的(anonymous composition)。 

通过嵌入一个匿名类型的组合实现了继承。 嵌入的结构体等同于基类(base class)。当然了也可以嵌入一个接口，但是必须注意，嵌入一个接口时，该结构体必须实现这个接口的方法，不然会报runtime error。

报错：panic: runtime error: invalid memory address or nil pointer dereference
</code></pre><ol start="3">
<li><p>多态（polymorphism）</p>
<p> 多态是允许你将父对象设置成为和一个或更多的子对象相等的技术。赋值会后，父对象就可以根据当前赋值给它的子对象以不同的方式运作。简单来说，允许将子类类型的指针赋值给父类类型的指针。 在C++中都是通过虚函数(Virtual Function)实现的。golang允许接口的子类的多态，但不允许子类替换为父类</p>
</li>
</ol>
<h3 id="实际例子"><a href="#实际例子" class="headerlink" title="实际例子"></a>实际例子</h3><p>在我们实际项目中用到多态的地方很多，举一个例子 获取下游服务的节点列表：<br>需求：</p>
<ul>
<li>希望支持多种方式获取节点列表，比如配置文件、服务发现、http请求等；</li>
<li>希望通过配置获取顺序的方式来实现优先级，比如配置是<code>get_type=服务发现,配置文件,http请求</code>。那么当服务发现获取节点成功时，则使用服务发现；反之如果服务发现获取节点列表失败，则需要使用配置文件的方式。</li>
</ul>
<p>抽象：</p>
<ul>
<li>定义一个接口IConfObj：</li>
<li><p>check函数：为了检查配置文件的配置项是否完备，因为不通获取方式，配置文件不一样；</p>
<pre><code>+ run函数：执行节点获取，并执行 InterfaceAction来执行节点更新。
</code></pre><ul>
<li><p>定义一个获取节点后动作的func，目的就是在获取节点后，通过该func进行操作。         </p>
<pre><code>type IConfObj interface {
    check() error
    run() (bool, error)
}

type InterfaceAction func(hosts []string, is_high_node, is_primary bool) (bool, error)
</code></pre></li>
<li><p>实现节点列表获取配置化</p>
<ul>
<li>不同的获取获取方式实现这个接口，并进行注册。</li>
<li>根据注册先后顺序执行run，如果run成功则结束遍历，反之继续执行直至成功。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>参考文章：</p>
<p><a href="https://code.tutsplus.com/tutorials/lets-go-object-oriented-programming-in-golang--cms-26540" target="_blank" rel="noopener">https://code.tutsplus.com/tutorials/lets-go-object-oriented-programming-in-golang--cms-26540</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2019/03/02/golang-面向对象编程/" data-id="ckwdj16qg002jsrnumn3sgfg2" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/golang/">golang</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-hive的TRANSFORM操作" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/23/hive的TRANSFORM操作/" class="article-date">
  <time datetime="2018-09-23T15:03:39.000Z" itemprop="datePublished">2018-09-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/23/hive的TRANSFORM操作/">hive的TRANSFORM操作</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Transform-Map-Reduce-Syntax"><a href="#Transform-Map-Reduce-Syntax" class="headerlink" title="Transform/Map-Reduce Syntax"></a>Transform/Map-Reduce Syntax</h2><p>hive语言中内置的特性是支持用户自定义mappers/redulers的。 用户可以使用<code>TRANSFROM</code> 子句来内嵌mapper/reduer脚本的。 </p>
<p>By default, columns will be transformed to STRING and delimited by TAB before feeding to the user script; similarly, all NULL values will be converted to the literal string \N in order to differentiate NULL values from empty strings. The standard output of the user script will be treated as TAB-separated STRING columns, any cell containing only \N will be re-interpreted as a NULL, and then the resulting STRING column will be cast to the data type specified in the table declaration in the usual way. User scripts can output debug information to standard error which will be shown on the task detail page on hadoop. These defaults can be overridden with ROW FORMAT ….</p>
<p>注意：</p>
<p>Formally, MAP … and REDUCE … are syntactic transformations of SELECT TRANSFORM ( … ). In other words, they serve as comments or notes to the reader of the query. BEWARE: Use of these keywords may be dangerous as (e.g.) typing “REDUCE” does not force a reduce phase to occur and typing “MAP” does not force a new map phase!</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">clusterBy: CLUSTER BY colName (&apos;,&apos; colName)*</span><br><span class="line">distributeBy: DISTRIBUTE BY colName (&apos;,&apos; colName)*</span><br><span class="line">sortBy: SORT BY colName (ASC | DESC)? (&apos;,&apos; colName (ASC | DESC)?)*</span><br><span class="line"> </span><br><span class="line">rowFormat</span><br><span class="line">  : ROW FORMAT</span><br><span class="line">    (DELIMITED [FIELDS TERMINATED BY char]</span><br><span class="line">               [COLLECTION ITEMS TERMINATED BY char]</span><br><span class="line">               [MAP KEYS TERMINATED BY char]</span><br><span class="line">               [ESCAPED BY char]</span><br><span class="line">               [LINES SEPARATED BY char]</span><br><span class="line">     |</span><br><span class="line">     SERDE serde_name [WITH SERDEPROPERTIES</span><br><span class="line">                            property_name=property_value,</span><br><span class="line">                            property_name=property_value, ...])</span><br><span class="line"> </span><br><span class="line">outRowFormat : rowFormat</span><br><span class="line">inRowFormat : rowFormat</span><br><span class="line">outRecordReader : RECORDREADER className</span><br><span class="line"> </span><br><span class="line">query:</span><br><span class="line">  FROM (</span><br><span class="line">    FROM src</span><br><span class="line">    MAP expression (&apos;,&apos; expression)*</span><br><span class="line">    (inRowFormat)?</span><br><span class="line">    USING &apos;my_map_script&apos;</span><br><span class="line">    ( AS colName (&apos;,&apos; colName)* )?</span><br><span class="line">    (outRowFormat)? (outRecordReader)?</span><br><span class="line">    ( clusterBy? | distributeBy? sortBy? ) src_alias</span><br><span class="line">  )</span><br><span class="line">  REDUCE expression (&apos;,&apos; expression)*</span><br><span class="line">    (inRowFormat)?</span><br><span class="line">    USING &apos;my_reduce_script&apos;</span><br><span class="line">    ( AS colName (&apos;,&apos; colName)* )?</span><br><span class="line">    (outRowFormat)? (outRecordReader)?</span><br><span class="line"> </span><br><span class="line">  FROM (</span><br><span class="line">    FROM src</span><br><span class="line">    SELECT TRANSFORM &apos;(&apos; expression (&apos;,&apos; expression)* &apos;)&apos;</span><br><span class="line">    (inRowFormat)?</span><br><span class="line">    USING &apos;my_map_script&apos;</span><br><span class="line">    ( AS colName (&apos;,&apos; colName)* )?</span><br><span class="line">    (outRowFormat)? (outRecordReader)?</span><br><span class="line">    ( clusterBy? | distributeBy? sortBy? ) src_alias</span><br><span class="line">  )</span><br><span class="line">  SELECT TRANSFORM &apos;(&apos; expression (&apos;,&apos; expression)* &apos;)&apos;</span><br><span class="line">    (inRowFormat)?</span><br><span class="line">    USING &apos;my_reduce_script&apos;</span><br><span class="line">    ( AS colName (&apos;,&apos; colName)* )?</span><br><span class="line">    (outRowFormat)? (outRecordReader)?</span><br></pre></td></tr></table></figure>
<p>转化的例子1：</p>
<p><code>FROM (
  FROM pv_users
  MAP pv_users.userid, pv_users.date
  USING &#39;map_script&#39;
  AS dt, uid
  CLUSTER BY dt) map_output
INSERT OVERWRITE TABLE pv_users_reduced
  REDUCE map_output.dt, map_output.uid
  USING &#39;reduce_script&#39;
  AS date, count;
FROM (
  FROM pv_users
  SELECT TRANSFORM(pv_users.userid, pv_users.date)
  USING &#39;map_script&#39;
  AS dt, uid
  CLUSTER BY dt) map_output
INSERT OVERWRITE TABLE pv_users_reduced
  SELECT TRANSFORM(map_output.dt, map_output.uid)
  USING &#39;reduce_script&#39;
  AS date, count;</code></p>
<p>转化的例子2：</p>
<p><code>FROM (
  FROM src
  SELECT TRANSFORM(src.key, src.value) ROW FORMAT SERDE &#39;org.apache.hadoop.hive.contrib.serde2.TypedBytesSerDe&#39;
  USING &#39;/bin/cat&#39;
  AS (tkey, tvalue) ROW FORMAT SERDE &#39;org.apache.hadoop.hive.contrib.serde2.TypedBytesSerDe&#39;
  RECORDREADER &#39;org.apache.hadoop.hive.contrib.util.typedbytes.TypedBytesRecordReader&#39;
) tmap
INSERT OVERWRITE TABLE dest1 SELECT tkey, tvalue</code></p>
<p>将TRANSFORM的输出打出来</p>
<p>脚本的输出默认是string，如果想进行类型转换的需要进行如下操作。</p>
<p><code>SELECT TRANSFORM(stuff)
USING &#39;script&#39;
AS thing1, thing2</code></p>
<p>类型转化<br><code>SELECT TRANSFORM(stuff)
USING &#39;script&#39;
AS (thing1 INT, thing2 INT)</code></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://keything.github.io/2018/09/23/hive的TRANSFORM操作/" data-id="ckwdj16qj002qsrnuys4xyoyg" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Laravel/">Laravel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Redis/">Redis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/composer/">composer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cpp/">cpp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cpp-lib/">cpp-lib</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/faiss/">faiss</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/">git</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go-source-code/">go.source.code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/golang/">golang</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/laravel/">laravel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mac/">mac</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/">machine-learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/memcache/">memcache</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/">mysql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nginx/">nginx</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nosql/">nosql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/octave/">octave</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/php/">php</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/php源码学习/">php源码学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/redis/">redis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/">spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tcp/">tcp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/thrift/">thrift</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分布式/">分布式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/基础知识/">基础知识</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Laravel/" style="font-size: 10px;">Laravel</a> <a href="/tags/Redis/" style="font-size: 10px;">Redis</a> <a href="/tags/composer/" style="font-size: 10px;">composer</a> <a href="/tags/cpp/" style="font-size: 12.22px;">cpp</a> <a href="/tags/cpp-lib/" style="font-size: 10px;">cpp-lib</a> <a href="/tags/elasticsearch/" style="font-size: 11.11px;">elasticsearch</a> <a href="/tags/faiss/" style="font-size: 10px;">faiss</a> <a href="/tags/git/" style="font-size: 12.22px;">git</a> <a href="/tags/go-source-code/" style="font-size: 10px;">go.source.code</a> <a href="/tags/golang/" style="font-size: 16.67px;">golang</a> <a href="/tags/laravel/" style="font-size: 11.11px;">laravel</a> <a href="/tags/linux/" style="font-size: 14.44px;">linux</a> <a href="/tags/mac/" style="font-size: 13.33px;">mac</a> <a href="/tags/machine-learning/" style="font-size: 10px;">machine-learning</a> <a href="/tags/memcache/" style="font-size: 15.56px;">memcache</a> <a href="/tags/mysql/" style="font-size: 13.33px;">mysql</a> <a href="/tags/nginx/" style="font-size: 13.33px;">nginx</a> <a href="/tags/nosql/" style="font-size: 18.89px;">nosql</a> <a href="/tags/octave/" style="font-size: 10px;">octave</a> <a href="/tags/php/" style="font-size: 20px;">php</a> <a href="/tags/php源码学习/" style="font-size: 17.78px;">php源码学习</a> <a href="/tags/redis/" style="font-size: 12.22px;">redis</a> <a href="/tags/spark/" style="font-size: 12.22px;">spark</a> <a href="/tags/tcp/" style="font-size: 10px;">tcp</a> <a href="/tags/thrift/" style="font-size: 13.33px;">thrift</a> <a href="/tags/分布式/" style="font-size: 12.22px;">分布式</a> <a href="/tags/基础知识/" style="font-size: 15.56px;">基础知识</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">December 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">November 2015</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/11/24/分布式-广播/">分布式-广播</a>
          </li>
        
          <li>
            <a href="/2021/11/19/分布式-CAP理论/">分布式-CAP理论</a>
          </li>
        
          <li>
            <a href="/2021/11/16/Spark-DataSource-Hive Tables/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/11/14/分布式-事务/">分布式-事务</a>
          </li>
        
          <li>
            <a href="/2019/04/29/golang继承/">golang继承</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 Keything<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>